{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7425aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a9ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SeniorCitizen",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tenure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PhoneService",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaperlessBilling",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MonthlyCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TotalCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Churn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_Month-to-Month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_One year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_Two year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Bank transfer (automatic)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Credit card (automatic)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Electronic check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Mailed check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender_Female",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_DSL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_Fiber optic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_Yes",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1841638f-4b37-4e22-8591-f975581fe187",
       "rows": [
        [
         "0",
         "0",
         "-0.2441995978989742",
         "1",
         "1",
         "0.0210828941063727",
         "0.0013911071014704",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "1",
         "1",
         "-0.3067479778476306",
         "1",
         "0",
         "0.053733035491338",
         "0.0026127642849414",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2",
         "0",
         "-0.7445866374882254",
         "1",
         "0",
         "0.0043933943864432",
         "0.000400889719128",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "3",
         "0",
         "1.06931638102281",
         "1",
         "1",
         "0.0205969887364435",
         "0.0028858231033112",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "0",
         "-0.6194898775909126",
         "1",
         "0",
         "0.0414436788435452",
         "0.0015349967870163",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 47,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Contract_Month-to-Month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection_Yes</th>\n",
       "      <th>TechSupport_No</th>\n",
       "      <th>TechSupport_Unknown</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_No</th>\n",
       "      <th>StreamingTV_Unknown</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <th>StreamingMovies_Unknown</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.244200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021083</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.306748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053733</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.744587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.069316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.619490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041444</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen    tenure  PhoneService  PaperlessBilling  MonthlyCharges  \\\n",
       "0              0 -0.244200             1                 1        0.021083   \n",
       "1              1 -0.306748             1                 0        0.053733   \n",
       "2              0 -0.744587             1                 0        0.004393   \n",
       "3              0  1.069316             1                 1        0.020597   \n",
       "4              0 -0.619490             1                 0        0.041444   \n",
       "\n",
       "   TotalCharges  Churn  Contract_Month-to-Month  Contract_One year  \\\n",
       "0      0.001391      0                        1                  0   \n",
       "1      0.002613      0                        0                  0   \n",
       "2      0.000401      0                        0                  1   \n",
       "3      0.002886      0                        0                  0   \n",
       "4      0.001535      0                        1                  0   \n",
       "\n",
       "   Contract_Two year  ...  DeviceProtection_Yes  TechSupport_No  \\\n",
       "0                  0  ...                     0               1   \n",
       "1                  1  ...                     0               1   \n",
       "2                  0  ...                     0               1   \n",
       "3                  1  ...                     0               1   \n",
       "4                  0  ...                     1               1   \n",
       "\n",
       "   TechSupport_Unknown  TechSupport_Yes  StreamingTV_No  StreamingTV_Unknown  \\\n",
       "0                    0                0               0                    0   \n",
       "1                    0                0               1                    0   \n",
       "2                    0                0               1                    0   \n",
       "3                    0                0               1                    0   \n",
       "4                    0                0               1                    0   \n",
       "\n",
       "   StreamingTV_Yes  StreamingMovies_No  StreamingMovies_Unknown  \\\n",
       "0                1                   0                        0   \n",
       "1                0                   1                        0   \n",
       "2                0                   1                        0   \n",
       "3                0                   1                        0   \n",
       "4                0                   1                        0   \n",
       "\n",
       "   StreamingMovies_Yes  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('04.reduced_telco_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602b0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign X (all columns except 'Churn')\n",
    "# X = data.drop(columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691163e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign Y (only 'Churn')\n",
    "# Y = data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"X shape:\", X.shape)  \n",
    "# X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c513df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Y shape:\", Y.shape) \n",
    "# Y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce463afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train-test split (80% train, 20% test)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72567ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train-test split done!\")\n",
    "# print(\"Train size:\", X_train.shape, Y_train.shape)\n",
    "# print(\"Test size:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fa8ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save them to train_test_split_dataset folder\n",
    "# X_train.to_csv(\"../Train_test_dataset/X_train.csv\", index=False)\n",
    "# X_test.to_csv(\"../Train_test_dataset/X_test.csv\", index=False)\n",
    "# Y_train.to_csv(\"../Train_test_dataset/Y_train.csv\", index=False)\n",
    "# Y_test.to_csv(\"../Train_test_dataset/Y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff638c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   SeniorCitizen                            56000 non-null  int64  \n",
      " 1   tenure                                   56000 non-null  float64\n",
      " 2   PhoneService                             56000 non-null  int64  \n",
      " 3   PaperlessBilling                         56000 non-null  int64  \n",
      " 4   MonthlyCharges                           56000 non-null  float64\n",
      " 5   TotalCharges                             56000 non-null  float64\n",
      " 6   Churn                                    56000 non-null  int64  \n",
      " 7   Contract_Month-to-Month                  56000 non-null  int64  \n",
      " 8   Contract_One year                        56000 non-null  int64  \n",
      " 9   Contract_Two year                        56000 non-null  int64  \n",
      " 10  PaymentMethod_Bank transfer (automatic)  56000 non-null  int64  \n",
      " 11  PaymentMethod_Credit card (automatic)    56000 non-null  int64  \n",
      " 12  PaymentMethod_Electronic check           56000 non-null  int64  \n",
      " 13  PaymentMethod_Mailed check               56000 non-null  int64  \n",
      " 14  PaymentMethod_Unknown                    56000 non-null  int64  \n",
      " 15  gender_Female                            56000 non-null  int64  \n",
      " 16  gender_Unknown                           56000 non-null  int64  \n",
      " 17  Partner_No                               56000 non-null  int64  \n",
      " 18  Partner_Unknown                          56000 non-null  int64  \n",
      " 19  Partner_Yes                              56000 non-null  int64  \n",
      " 20  Dependents_No                            56000 non-null  int64  \n",
      " 21  Dependents_Unknown                       56000 non-null  int64  \n",
      " 22  Dependents_Yes                           56000 non-null  int64  \n",
      " 23  MultipleLines_No                         56000 non-null  int64  \n",
      " 24  MultipleLines_Unknown                    56000 non-null  int64  \n",
      " 25  MultipleLines_Yes                        56000 non-null  int64  \n",
      " 26  InternetService_DSL                      56000 non-null  int64  \n",
      " 27  InternetService_Fiber optic              56000 non-null  int64  \n",
      " 28  InternetService_No                       56000 non-null  int64  \n",
      " 29  OnlineSecurity_No                        56000 non-null  int64  \n",
      " 30  OnlineSecurity_Unknown                   56000 non-null  int64  \n",
      " 31  OnlineSecurity_Yes                       56000 non-null  int64  \n",
      " 32  OnlineBackup_No                          56000 non-null  int64  \n",
      " 33  OnlineBackup_Unknown                     56000 non-null  int64  \n",
      " 34  OnlineBackup_Yes                         56000 non-null  int64  \n",
      " 35  DeviceProtection_No                      56000 non-null  int64  \n",
      " 36  DeviceProtection_Unknown                 56000 non-null  int64  \n",
      " 37  DeviceProtection_Yes                     56000 non-null  int64  \n",
      " 38  TechSupport_No                           56000 non-null  int64  \n",
      " 39  TechSupport_Unknown                      56000 non-null  int64  \n",
      " 40  TechSupport_Yes                          56000 non-null  int64  \n",
      " 41  StreamingTV_No                           56000 non-null  int64  \n",
      " 42  StreamingTV_Unknown                      56000 non-null  int64  \n",
      " 43  StreamingTV_Yes                          56000 non-null  int64  \n",
      " 44  StreamingMovies_No                       56000 non-null  int64  \n",
      " 45  StreamingMovies_Unknown                  56000 non-null  int64  \n",
      " 46  StreamingMovies_Yes                      56000 non-null  int64  \n",
      "dtypes: float64(3), int64(44)\n",
      "memory usage: 20.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96fe6561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], shape=(56000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,6].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0482eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.drop(data.columns[6], axis=1)\n",
    "X = tmp.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041888b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.2441996 ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , -0.30674798,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.74458664,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.6940261 ,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.30674798,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        , -1.24497368,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ]], shape=(56000, 46))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc66c521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29762, 26238])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(y) # *output-> [0 count, 1 count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f955ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.2,\n",
    "    random_state= 42,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0eb9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5587839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.6322518 , 1.        , 1.        , 0.00771375,\n",
       "       0.00214425, 0.        , 1.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4055fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4dec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7346055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b5b2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(64, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(16, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d626fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,081</span> (23.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,081\u001b[0m (23.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,857</span> (22.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,857\u001b[0m (22.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "880099e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),  # Area Under the Curve (ROC)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f87e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   SeniorCitizen                            56000 non-null  int64  \n",
      " 1   tenure                                   56000 non-null  float64\n",
      " 2   PhoneService                             56000 non-null  int64  \n",
      " 3   PaperlessBilling                         56000 non-null  int64  \n",
      " 4   MonthlyCharges                           56000 non-null  float64\n",
      " 5   TotalCharges                             56000 non-null  float64\n",
      " 6   Churn                                    56000 non-null  int64  \n",
      " 7   Contract_Month-to-Month                  56000 non-null  int64  \n",
      " 8   Contract_One year                        56000 non-null  int64  \n",
      " 9   Contract_Two year                        56000 non-null  int64  \n",
      " 10  PaymentMethod_Bank transfer (automatic)  56000 non-null  int64  \n",
      " 11  PaymentMethod_Credit card (automatic)    56000 non-null  int64  \n",
      " 12  PaymentMethod_Electronic check           56000 non-null  int64  \n",
      " 13  PaymentMethod_Mailed check               56000 non-null  int64  \n",
      " 14  PaymentMethod_Unknown                    56000 non-null  int64  \n",
      " 15  gender_Female                            56000 non-null  int64  \n",
      " 16  gender_Unknown                           56000 non-null  int64  \n",
      " 17  Partner_No                               56000 non-null  int64  \n",
      " 18  Partner_Unknown                          56000 non-null  int64  \n",
      " 19  Partner_Yes                              56000 non-null  int64  \n",
      " 20  Dependents_No                            56000 non-null  int64  \n",
      " 21  Dependents_Unknown                       56000 non-null  int64  \n",
      " 22  Dependents_Yes                           56000 non-null  int64  \n",
      " 23  MultipleLines_No                         56000 non-null  int64  \n",
      " 24  MultipleLines_Unknown                    56000 non-null  int64  \n",
      " 25  MultipleLines_Yes                        56000 non-null  int64  \n",
      " 26  InternetService_DSL                      56000 non-null  int64  \n",
      " 27  InternetService_Fiber optic              56000 non-null  int64  \n",
      " 28  InternetService_No                       56000 non-null  int64  \n",
      " 29  OnlineSecurity_No                        56000 non-null  int64  \n",
      " 30  OnlineSecurity_Unknown                   56000 non-null  int64  \n",
      " 31  OnlineSecurity_Yes                       56000 non-null  int64  \n",
      " 32  OnlineBackup_No                          56000 non-null  int64  \n",
      " 33  OnlineBackup_Unknown                     56000 non-null  int64  \n",
      " 34  OnlineBackup_Yes                         56000 non-null  int64  \n",
      " 35  DeviceProtection_No                      56000 non-null  int64  \n",
      " 36  DeviceProtection_Unknown                 56000 non-null  int64  \n",
      " 37  DeviceProtection_Yes                     56000 non-null  int64  \n",
      " 38  TechSupport_No                           56000 non-null  int64  \n",
      " 39  TechSupport_Unknown                      56000 non-null  int64  \n",
      " 40  TechSupport_Yes                          56000 non-null  int64  \n",
      " 41  StreamingTV_No                           56000 non-null  int64  \n",
      " 42  StreamingTV_Unknown                      56000 non-null  int64  \n",
      " 43  StreamingTV_Yes                          56000 non-null  int64  \n",
      " 44  StreamingMovies_No                       56000 non-null  int64  \n",
      " 45  StreamingMovies_Unknown                  56000 non-null  int64  \n",
      " 46  StreamingMovies_Yes                      56000 non-null  int64  \n",
      "dtypes: float64(3), int64(44)\n",
      "memory usage: 20.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f95dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.7015 - auc: 0.7510 - loss: 0.5901 - precision: 0.6720 - recall: 0.7088 - val_accuracy: 0.7642 - val_auc: 0.7807 - val_loss: 0.5216 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 2/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7250 - auc: 0.7681 - loss: 0.5670 - precision: 0.6865 - recall: 0.7601 - val_accuracy: 0.7642 - val_auc: 0.7844 - val_loss: 0.5210 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 3/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7250 - auc: 0.7711 - loss: 0.5637 - precision: 0.6874 - recall: 0.7574 - val_accuracy: 0.7642 - val_auc: 0.7832 - val_loss: 0.5197 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 4/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7263 - auc: 0.7730 - loss: 0.5621 - precision: 0.6891 - recall: 0.7576 - val_accuracy: 0.7642 - val_auc: 0.7809 - val_loss: 0.5183 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 5/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7249 - auc: 0.7738 - loss: 0.5614 - precision: 0.6886 - recall: 0.7535 - val_accuracy: 0.7642 - val_auc: 0.7807 - val_loss: 0.5192 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 6/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7252 - auc: 0.7751 - loss: 0.5601 - precision: 0.6891 - recall: 0.7532 - val_accuracy: 0.7642 - val_auc: 0.7809 - val_loss: 0.5190 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 7/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7259 - auc: 0.7759 - loss: 0.5595 - precision: 0.6901 - recall: 0.7530 - val_accuracy: 0.7642 - val_auc: 0.7816 - val_loss: 0.5176 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 8/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7275 - auc: 0.7761 - loss: 0.5592 - precision: 0.6920 - recall: 0.7541 - val_accuracy: 0.7642 - val_auc: 0.7815 - val_loss: 0.5185 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 9/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7293 - auc: 0.7777 - loss: 0.5581 - precision: 0.6929 - recall: 0.7582 - val_accuracy: 0.7642 - val_auc: 0.7798 - val_loss: 0.5196 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 10/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7294 - auc: 0.7777 - loss: 0.5577 - precision: 0.6935 - recall: 0.7571 - val_accuracy: 0.7642 - val_auc: 0.7802 - val_loss: 0.5199 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 11/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7283 - auc: 0.7780 - loss: 0.5577 - precision: 0.6925 - recall: 0.7556 - val_accuracy: 0.7642 - val_auc: 0.7797 - val_loss: 0.5194 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 12/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7307 - auc: 0.7802 - loss: 0.5559 - precision: 0.6952 - recall: 0.7570 - val_accuracy: 0.7642 - val_auc: 0.7801 - val_loss: 0.5201 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 13/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7300 - auc: 0.7798 - loss: 0.5560 - precision: 0.6958 - recall: 0.7528 - val_accuracy: 0.7642 - val_auc: 0.7803 - val_loss: 0.5198 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 14/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7314 - auc: 0.7808 - loss: 0.5547 - precision: 0.6956 - recall: 0.7584 - val_accuracy: 0.7642 - val_auc: 0.7799 - val_loss: 0.5203 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 15/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7294 - auc: 0.7814 - loss: 0.5553 - precision: 0.6954 - recall: 0.7515 - val_accuracy: 0.7642 - val_auc: 0.7800 - val_loss: 0.5198 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 16/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.7306 - auc: 0.7828 - loss: 0.5536 - precision: 0.6968 - recall: 0.7520 - val_accuracy: 0.7641 - val_auc: 0.7798 - val_loss: 0.5193 - val_precision: 0.6940 - val_recall: 0.8886\n",
      "Epoch 17/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7318 - auc: 0.7834 - loss: 0.5530 - precision: 0.6972 - recall: 0.7556 - val_accuracy: 0.7642 - val_auc: 0.7790 - val_loss: 0.5193 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 18/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.7335 - auc: 0.7837 - loss: 0.5524 - precision: 0.6988 - recall: 0.7579 - val_accuracy: 0.7642 - val_auc: 0.7802 - val_loss: 0.5192 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 19/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.7343 - auc: 0.7839 - loss: 0.5521 - precision: 0.7005 - recall: 0.7560 - val_accuracy: 0.7642 - val_auc: 0.7796 - val_loss: 0.5213 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 20/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7317 - auc: 0.7847 - loss: 0.5518 - precision: 0.6981 - recall: 0.7528 - val_accuracy: 0.7642 - val_auc: 0.7788 - val_loss: 0.5197 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 21/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7358 - auc: 0.7856 - loss: 0.5504 - precision: 0.7001 - recall: 0.7629 - val_accuracy: 0.7641 - val_auc: 0.7785 - val_loss: 0.5201 - val_precision: 0.6940 - val_recall: 0.8886\n",
      "Epoch 22/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7348 - auc: 0.7855 - loss: 0.5514 - precision: 0.7010 - recall: 0.7567 - val_accuracy: 0.7642 - val_auc: 0.7793 - val_loss: 0.5198 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 23/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7344 - auc: 0.7862 - loss: 0.5506 - precision: 0.6997 - recall: 0.7585 - val_accuracy: 0.7642 - val_auc: 0.7793 - val_loss: 0.5207 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 24/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7343 - auc: 0.7864 - loss: 0.5501 - precision: 0.6992 - recall: 0.7593 - val_accuracy: 0.7641 - val_auc: 0.7800 - val_loss: 0.5205 - val_precision: 0.6940 - val_recall: 0.8886\n",
      "Epoch 25/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7353 - auc: 0.7872 - loss: 0.5501 - precision: 0.7013 - recall: 0.7576 - val_accuracy: 0.7640 - val_auc: 0.7800 - val_loss: 0.5210 - val_precision: 0.6939 - val_recall: 0.8884\n",
      "Epoch 26/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7384 - auc: 0.7891 - loss: 0.5483 - precision: 0.7044 - recall: 0.7609 - val_accuracy: 0.7641 - val_auc: 0.7790 - val_loss: 0.5224 - val_precision: 0.6940 - val_recall: 0.8886\n",
      "Epoch 27/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7364 - auc: 0.7898 - loss: 0.5472 - precision: 0.7025 - recall: 0.7583 - val_accuracy: 0.7640 - val_auc: 0.7793 - val_loss: 0.5216 - val_precision: 0.6939 - val_recall: 0.8884\n",
      "Epoch 28/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7368 - auc: 0.7886 - loss: 0.5480 - precision: 0.7025 - recall: 0.7600 - val_accuracy: 0.7641 - val_auc: 0.7799 - val_loss: 0.5218 - val_precision: 0.6940 - val_recall: 0.8886\n",
      "Epoch 29/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7384 - auc: 0.7892 - loss: 0.5476 - precision: 0.7046 - recall: 0.7603 - val_accuracy: 0.7642 - val_auc: 0.7801 - val_loss: 0.5202 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 30/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7370 - auc: 0.7899 - loss: 0.5471 - precision: 0.7036 - recall: 0.7579 - val_accuracy: 0.7642 - val_auc: 0.7818 - val_loss: 0.5215 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 31/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7397 - auc: 0.7910 - loss: 0.5464 - precision: 0.7061 - recall: 0.7612 - val_accuracy: 0.7642 - val_auc: 0.7802 - val_loss: 0.5212 - val_precision: 0.6941 - val_recall: 0.8888\n",
      "Epoch 32/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7410 - auc: 0.7914 - loss: 0.5457 - precision: 0.7084 - recall: 0.7598 - val_accuracy: 0.7641 - val_auc: 0.7819 - val_loss: 0.5208 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 33/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7381 - auc: 0.7908 - loss: 0.5465 - precision: 0.7058 - recall: 0.7560 - val_accuracy: 0.7638 - val_auc: 0.7813 - val_loss: 0.5232 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 34/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7400 - auc: 0.7910 - loss: 0.5462 - precision: 0.7068 - recall: 0.7606 - val_accuracy: 0.7640 - val_auc: 0.7803 - val_loss: 0.5231 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 35/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7383 - auc: 0.7911 - loss: 0.5460 - precision: 0.7058 - recall: 0.7567 - val_accuracy: 0.7641 - val_auc: 0.7795 - val_loss: 0.5217 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 36/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7406 - auc: 0.7921 - loss: 0.5451 - precision: 0.7086 - recall: 0.7579 - val_accuracy: 0.7642 - val_auc: 0.7799 - val_loss: 0.5216 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 37/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7385 - auc: 0.7917 - loss: 0.5459 - precision: 0.7060 - recall: 0.7571 - val_accuracy: 0.7641 - val_auc: 0.7802 - val_loss: 0.5216 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 38/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7385 - auc: 0.7930 - loss: 0.5450 - precision: 0.7061 - recall: 0.7568 - val_accuracy: 0.7640 - val_auc: 0.7810 - val_loss: 0.5222 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 39/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7407 - auc: 0.7937 - loss: 0.5440 - precision: 0.7090 - recall: 0.7573 - val_accuracy: 0.7642 - val_auc: 0.7807 - val_loss: 0.5239 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 40/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7408 - auc: 0.7936 - loss: 0.5446 - precision: 0.7092 - recall: 0.7572 - val_accuracy: 0.7641 - val_auc: 0.7823 - val_loss: 0.5229 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 41/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7425 - auc: 0.7945 - loss: 0.5431 - precision: 0.7099 - recall: 0.7616 - val_accuracy: 0.7642 - val_auc: 0.7827 - val_loss: 0.5227 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 42/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7375 - auc: 0.7927 - loss: 0.5457 - precision: 0.7057 - recall: 0.7539 - val_accuracy: 0.7641 - val_auc: 0.7815 - val_loss: 0.5233 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 43/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7403 - auc: 0.7939 - loss: 0.5440 - precision: 0.7076 - recall: 0.7593 - val_accuracy: 0.7638 - val_auc: 0.7811 - val_loss: 0.5239 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 44/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7396 - auc: 0.7941 - loss: 0.5439 - precision: 0.7083 - recall: 0.7551 - val_accuracy: 0.7638 - val_auc: 0.7812 - val_loss: 0.5227 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 45/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.7409 - auc: 0.7965 - loss: 0.5419 - precision: 0.7100 - recall: 0.7555 - val_accuracy: 0.7635 - val_auc: 0.7804 - val_loss: 0.5244 - val_precision: 0.6939 - val_recall: 0.8869\n",
      "Epoch 46/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.7404 - auc: 0.7945 - loss: 0.5434 - precision: 0.7092 - recall: 0.7556 - val_accuracy: 0.7640 - val_auc: 0.7807 - val_loss: 0.5231 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 47/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.7390 - auc: 0.7954 - loss: 0.5428 - precision: 0.7081 - recall: 0.7535 - val_accuracy: 0.7641 - val_auc: 0.7805 - val_loss: 0.5246 - val_precision: 0.6941 - val_recall: 0.8881\n",
      "Epoch 48/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7411 - auc: 0.7950 - loss: 0.5430 - precision: 0.7110 - recall: 0.7538 - val_accuracy: 0.7640 - val_auc: 0.7802 - val_loss: 0.5247 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 49/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7439 - auc: 0.7972 - loss: 0.5408 - precision: 0.7125 - recall: 0.7602 - val_accuracy: 0.7642 - val_auc: 0.7806 - val_loss: 0.5225 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 50/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7411 - auc: 0.7952 - loss: 0.5434 - precision: 0.7108 - recall: 0.7541 - val_accuracy: 0.7643 - val_auc: 0.7815 - val_loss: 0.5239 - val_precision: 0.6942 - val_recall: 0.8888\n",
      "Epoch 51/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7417 - auc: 0.7964 - loss: 0.5417 - precision: 0.7104 - recall: 0.7574 - val_accuracy: 0.7641 - val_auc: 0.7821 - val_loss: 0.5212 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 52/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7401 - auc: 0.7952 - loss: 0.5427 - precision: 0.7085 - recall: 0.7563 - val_accuracy: 0.7637 - val_auc: 0.7815 - val_loss: 0.5225 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 53/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7414 - auc: 0.7969 - loss: 0.5410 - precision: 0.7098 - recall: 0.7579 - val_accuracy: 0.7638 - val_auc: 0.7822 - val_loss: 0.5243 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 54/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7405 - auc: 0.7978 - loss: 0.5405 - precision: 0.7101 - recall: 0.7537 - val_accuracy: 0.7638 - val_auc: 0.7819 - val_loss: 0.5252 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 55/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7424 - auc: 0.7968 - loss: 0.5417 - precision: 0.7118 - recall: 0.7562 - val_accuracy: 0.7638 - val_auc: 0.7814 - val_loss: 0.5243 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 56/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7438 - auc: 0.7979 - loss: 0.5405 - precision: 0.7138 - recall: 0.7563 - val_accuracy: 0.7641 - val_auc: 0.7826 - val_loss: 0.5237 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 57/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7429 - auc: 0.7986 - loss: 0.5398 - precision: 0.7129 - recall: 0.7553 - val_accuracy: 0.7638 - val_auc: 0.7809 - val_loss: 0.5265 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 58/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7430 - auc: 0.7983 - loss: 0.5404 - precision: 0.7124 - recall: 0.7569 - val_accuracy: 0.7635 - val_auc: 0.7808 - val_loss: 0.5253 - val_precision: 0.6939 - val_recall: 0.8869\n",
      "Epoch 59/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7431 - auc: 0.7981 - loss: 0.5406 - precision: 0.7131 - recall: 0.7556 - val_accuracy: 0.7635 - val_auc: 0.7813 - val_loss: 0.5256 - val_precision: 0.6938 - val_recall: 0.8872\n",
      "Epoch 60/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7419 - auc: 0.7974 - loss: 0.5415 - precision: 0.7122 - recall: 0.7533 - val_accuracy: 0.7638 - val_auc: 0.7806 - val_loss: 0.5272 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 61/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7450 - auc: 0.8000 - loss: 0.5392 - precision: 0.7153 - recall: 0.7570 - val_accuracy: 0.7638 - val_auc: 0.7810 - val_loss: 0.5246 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 62/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7425 - auc: 0.7990 - loss: 0.5396 - precision: 0.7124 - recall: 0.7553 - val_accuracy: 0.7642 - val_auc: 0.7806 - val_loss: 0.5252 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 63/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7440 - auc: 0.7984 - loss: 0.5405 - precision: 0.7140 - recall: 0.7567 - val_accuracy: 0.7642 - val_auc: 0.7800 - val_loss: 0.5255 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 64/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7437 - auc: 0.8001 - loss: 0.5388 - precision: 0.7147 - recall: 0.7538 - val_accuracy: 0.7642 - val_auc: 0.7802 - val_loss: 0.5266 - val_precision: 0.6941 - val_recall: 0.8886\n",
      "Epoch 65/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7442 - auc: 0.7989 - loss: 0.5399 - precision: 0.7138 - recall: 0.7576 - val_accuracy: 0.7641 - val_auc: 0.7808 - val_loss: 0.5255 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 66/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7433 - auc: 0.7983 - loss: 0.5405 - precision: 0.7132 - recall: 0.7560 - val_accuracy: 0.7641 - val_auc: 0.7809 - val_loss: 0.5239 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 67/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7413 - auc: 0.7985 - loss: 0.5403 - precision: 0.7103 - recall: 0.7560 - val_accuracy: 0.7638 - val_auc: 0.7814 - val_loss: 0.5245 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 68/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7430 - auc: 0.7989 - loss: 0.5395 - precision: 0.7134 - recall: 0.7544 - val_accuracy: 0.7638 - val_auc: 0.7815 - val_loss: 0.5236 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 69/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7429 - auc: 0.7996 - loss: 0.5393 - precision: 0.7134 - recall: 0.7543 - val_accuracy: 0.7643 - val_auc: 0.7821 - val_loss: 0.5244 - val_precision: 0.6942 - val_recall: 0.8888\n",
      "Epoch 70/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7444 - auc: 0.7994 - loss: 0.5394 - precision: 0.7148 - recall: 0.7561 - val_accuracy: 0.7642 - val_auc: 0.7826 - val_loss: 0.5237 - val_precision: 0.6942 - val_recall: 0.8884\n",
      "Epoch 71/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7445 - auc: 0.8007 - loss: 0.5383 - precision: 0.7148 - recall: 0.7563 - val_accuracy: 0.7641 - val_auc: 0.7828 - val_loss: 0.5267 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 72/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7437 - auc: 0.8003 - loss: 0.5380 - precision: 0.7144 - recall: 0.7547 - val_accuracy: 0.7641 - val_auc: 0.7829 - val_loss: 0.5236 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 73/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7446 - auc: 0.8013 - loss: 0.5371 - precision: 0.7144 - recall: 0.7576 - val_accuracy: 0.7638 - val_auc: 0.7823 - val_loss: 0.5262 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 74/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7427 - auc: 0.8016 - loss: 0.5377 - precision: 0.7133 - recall: 0.7537 - val_accuracy: 0.7629 - val_auc: 0.7812 - val_loss: 0.5265 - val_precision: 0.6937 - val_recall: 0.8853\n",
      "Epoch 75/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7422 - auc: 0.8006 - loss: 0.5386 - precision: 0.7134 - recall: 0.7517 - val_accuracy: 0.7636 - val_auc: 0.7809 - val_loss: 0.5250 - val_precision: 0.6939 - val_recall: 0.8872\n",
      "Epoch 76/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7445 - auc: 0.8005 - loss: 0.5383 - precision: 0.7150 - recall: 0.7559 - val_accuracy: 0.7640 - val_auc: 0.7815 - val_loss: 0.5228 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 77/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7444 - auc: 0.8015 - loss: 0.5377 - precision: 0.7161 - recall: 0.7528 - val_accuracy: 0.7640 - val_auc: 0.7823 - val_loss: 0.5251 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 78/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7442 - auc: 0.8010 - loss: 0.5379 - precision: 0.7149 - recall: 0.7551 - val_accuracy: 0.7641 - val_auc: 0.7816 - val_loss: 0.5266 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 79/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.7448 - auc: 0.8019 - loss: 0.5371 - precision: 0.7150 - recall: 0.7567 - val_accuracy: 0.7641 - val_auc: 0.7821 - val_loss: 0.5266 - val_precision: 0.6941 - val_recall: 0.8884\n",
      "Epoch 80/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7468 - auc: 0.8016 - loss: 0.5374 - precision: 0.7180 - recall: 0.7569 - val_accuracy: 0.7641 - val_auc: 0.7828 - val_loss: 0.5248 - val_precision: 0.6941 - val_recall: 0.8881\n",
      "Epoch 81/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7439 - auc: 0.8018 - loss: 0.5371 - precision: 0.7150 - recall: 0.7536 - val_accuracy: 0.7640 - val_auc: 0.7830 - val_loss: 0.5256 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 82/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.7484 - auc: 0.8025 - loss: 0.5369 - precision: 0.7203 - recall: 0.7568 - val_accuracy: 0.7642 - val_auc: 0.7828 - val_loss: 0.5247 - val_precision: 0.6942 - val_recall: 0.8884\n",
      "Epoch 83/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - accuracy: 0.7439 - auc: 0.8024 - loss: 0.5371 - precision: 0.7156 - recall: 0.7523 - val_accuracy: 0.7638 - val_auc: 0.7824 - val_loss: 0.5257 - val_precision: 0.6939 - val_recall: 0.8881\n",
      "Epoch 84/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.7450 - auc: 0.8022 - loss: 0.5372 - precision: 0.7172 - recall: 0.7522 - val_accuracy: 0.7640 - val_auc: 0.7816 - val_loss: 0.5253 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 85/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7455 - auc: 0.8024 - loss: 0.5366 - precision: 0.7168 - recall: 0.7551 - val_accuracy: 0.7637 - val_auc: 0.7818 - val_loss: 0.5239 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 86/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7435 - auc: 0.8022 - loss: 0.5370 - precision: 0.7147 - recall: 0.7529 - val_accuracy: 0.7633 - val_auc: 0.7806 - val_loss: 0.5262 - val_precision: 0.6939 - val_recall: 0.8860\n",
      "Epoch 87/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7459 - auc: 0.8027 - loss: 0.5365 - precision: 0.7165 - recall: 0.7571 - val_accuracy: 0.7640 - val_auc: 0.7809 - val_loss: 0.5256 - val_precision: 0.6940 - val_recall: 0.8881\n",
      "Epoch 88/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7438 - auc: 0.8034 - loss: 0.5356 - precision: 0.7155 - recall: 0.7521 - val_accuracy: 0.7632 - val_auc: 0.7809 - val_loss: 0.5270 - val_precision: 0.6938 - val_recall: 0.8860\n",
      "Epoch 89/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7441 - auc: 0.8026 - loss: 0.5363 - precision: 0.7152 - recall: 0.7539 - val_accuracy: 0.7638 - val_auc: 0.7802 - val_loss: 0.5262 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 90/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7447 - auc: 0.8034 - loss: 0.5358 - precision: 0.7166 - recall: 0.7528 - val_accuracy: 0.7637 - val_auc: 0.7812 - val_loss: 0.5267 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 91/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7444 - auc: 0.8015 - loss: 0.5375 - precision: 0.7166 - recall: 0.7516 - val_accuracy: 0.7637 - val_auc: 0.7824 - val_loss: 0.5256 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 92/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7441 - auc: 0.8024 - loss: 0.5367 - precision: 0.7168 - recall: 0.7500 - val_accuracy: 0.7634 - val_auc: 0.7807 - val_loss: 0.5275 - val_precision: 0.6938 - val_recall: 0.8867\n",
      "Epoch 93/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7458 - auc: 0.8039 - loss: 0.5358 - precision: 0.7189 - recall: 0.7510 - val_accuracy: 0.7633 - val_auc: 0.7817 - val_loss: 0.5259 - val_precision: 0.6937 - val_recall: 0.8865\n",
      "Epoch 94/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7451 - auc: 0.8040 - loss: 0.5352 - precision: 0.7176 - recall: 0.7517 - val_accuracy: 0.7636 - val_auc: 0.7820 - val_loss: 0.5253 - val_precision: 0.6938 - val_recall: 0.8874\n",
      "Epoch 95/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7448 - auc: 0.8035 - loss: 0.5355 - precision: 0.7166 - recall: 0.7531 - val_accuracy: 0.7629 - val_auc: 0.7830 - val_loss: 0.5273 - val_precision: 0.6934 - val_recall: 0.8865\n",
      "Epoch 96/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7441 - auc: 0.8029 - loss: 0.5363 - precision: 0.7158 - recall: 0.7528 - val_accuracy: 0.7637 - val_auc: 0.7820 - val_loss: 0.5276 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 97/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7463 - auc: 0.8038 - loss: 0.5351 - precision: 0.7179 - recall: 0.7553 - val_accuracy: 0.7638 - val_auc: 0.7824 - val_loss: 0.5282 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 98/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7443 - auc: 0.8026 - loss: 0.5365 - precision: 0.7166 - recall: 0.7513 - val_accuracy: 0.7641 - val_auc: 0.7820 - val_loss: 0.5249 - val_precision: 0.6941 - val_recall: 0.8881\n",
      "Epoch 99/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.7462 - auc: 0.8034 - loss: 0.5359 - precision: 0.7177 - recall: 0.7553 - val_accuracy: 0.7637 - val_auc: 0.7816 - val_loss: 0.5258 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 100/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7443 - auc: 0.8023 - loss: 0.5371 - precision: 0.7163 - recall: 0.7520 - val_accuracy: 0.7640 - val_auc: 0.7819 - val_loss: 0.5270 - val_precision: 0.6941 - val_recall: 0.8879\n",
      "Epoch 101/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7463 - auc: 0.8038 - loss: 0.5353 - precision: 0.7182 - recall: 0.7543 - val_accuracy: 0.7631 - val_auc: 0.7820 - val_loss: 0.5284 - val_precision: 0.6938 - val_recall: 0.8853\n",
      "Epoch 102/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - accuracy: 0.7452 - auc: 0.8040 - loss: 0.5353 - precision: 0.7181 - recall: 0.7508 - val_accuracy: 0.7638 - val_auc: 0.7828 - val_loss: 0.5278 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 103/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7463 - auc: 0.8051 - loss: 0.5342 - precision: 0.7190 - recall: 0.7525 - val_accuracy: 0.7636 - val_auc: 0.7828 - val_loss: 0.5284 - val_precision: 0.6939 - val_recall: 0.8872\n",
      "Epoch 104/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7482 - auc: 0.8047 - loss: 0.5343 - precision: 0.7202 - recall: 0.7563 - val_accuracy: 0.7628 - val_auc: 0.7822 - val_loss: 0.5288 - val_precision: 0.6937 - val_recall: 0.8850\n",
      "Epoch 105/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7469 - auc: 0.8051 - loss: 0.5346 - precision: 0.7195 - recall: 0.7533 - val_accuracy: 0.7636 - val_auc: 0.7825 - val_loss: 0.5281 - val_precision: 0.6938 - val_recall: 0.8874\n",
      "Epoch 106/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7481 - auc: 0.8052 - loss: 0.5343 - precision: 0.7206 - recall: 0.7551 - val_accuracy: 0.7637 - val_auc: 0.7818 - val_loss: 0.5267 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 107/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7457 - auc: 0.8044 - loss: 0.5349 - precision: 0.7181 - recall: 0.7526 - val_accuracy: 0.7633 - val_auc: 0.7818 - val_loss: 0.5287 - val_precision: 0.6937 - val_recall: 0.8865\n",
      "Epoch 108/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7448 - auc: 0.8039 - loss: 0.5356 - precision: 0.7163 - recall: 0.7537 - val_accuracy: 0.7636 - val_auc: 0.7823 - val_loss: 0.5280 - val_precision: 0.6938 - val_recall: 0.8876\n",
      "Epoch 109/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7467 - auc: 0.8045 - loss: 0.5356 - precision: 0.7192 - recall: 0.7533 - val_accuracy: 0.7638 - val_auc: 0.7817 - val_loss: 0.5287 - val_precision: 0.6941 - val_recall: 0.8874\n",
      "Epoch 110/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8075 - loss: 0.5315 - precision: 0.7203 - recall: 0.7550 - val_accuracy: 0.7635 - val_auc: 0.7833 - val_loss: 0.5298 - val_precision: 0.6937 - val_recall: 0.8874\n",
      "Epoch 111/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7454 - auc: 0.8054 - loss: 0.5337 - precision: 0.7177 - recall: 0.7524 - val_accuracy: 0.7637 - val_auc: 0.7830 - val_loss: 0.5267 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 112/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7449 - auc: 0.8041 - loss: 0.5356 - precision: 0.7178 - recall: 0.7503 - val_accuracy: 0.7638 - val_auc: 0.7827 - val_loss: 0.5288 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 113/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7454 - auc: 0.8044 - loss: 0.5349 - precision: 0.7185 - recall: 0.7506 - val_accuracy: 0.7634 - val_auc: 0.7830 - val_loss: 0.5262 - val_precision: 0.6938 - val_recall: 0.8867\n",
      "Epoch 114/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7455 - auc: 0.8030 - loss: 0.5363 - precision: 0.7178 - recall: 0.7524 - val_accuracy: 0.7638 - val_auc: 0.7822 - val_loss: 0.5272 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 115/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7462 - auc: 0.8042 - loss: 0.5349 - precision: 0.7183 - recall: 0.7540 - val_accuracy: 0.7638 - val_auc: 0.7835 - val_loss: 0.5264 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 116/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7454 - auc: 0.8042 - loss: 0.5348 - precision: 0.7175 - recall: 0.7529 - val_accuracy: 0.7637 - val_auc: 0.7849 - val_loss: 0.5250 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 117/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7466 - auc: 0.8052 - loss: 0.5336 - precision: 0.7185 - recall: 0.7548 - val_accuracy: 0.7635 - val_auc: 0.7831 - val_loss: 0.5263 - val_precision: 0.6939 - val_recall: 0.8869\n",
      "Epoch 118/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7465 - auc: 0.8041 - loss: 0.5347 - precision: 0.7173 - recall: 0.7570 - val_accuracy: 0.7633 - val_auc: 0.7830 - val_loss: 0.5266 - val_precision: 0.6938 - val_recall: 0.8862\n",
      "Epoch 119/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7451 - auc: 0.8053 - loss: 0.5342 - precision: 0.7170 - recall: 0.7532 - val_accuracy: 0.7634 - val_auc: 0.7831 - val_loss: 0.5267 - val_precision: 0.6937 - val_recall: 0.8869\n",
      "Epoch 120/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7480 - auc: 0.8060 - loss: 0.5333 - precision: 0.7221 - recall: 0.7510 - val_accuracy: 0.7632 - val_auc: 0.7843 - val_loss: 0.5262 - val_precision: 0.6937 - val_recall: 0.8862\n",
      "Epoch 121/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7443 - auc: 0.8050 - loss: 0.5348 - precision: 0.7171 - recall: 0.7500 - val_accuracy: 0.7635 - val_auc: 0.7833 - val_loss: 0.5287 - val_precision: 0.6939 - val_recall: 0.8869\n",
      "Epoch 122/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7470 - auc: 0.8047 - loss: 0.5352 - precision: 0.7205 - recall: 0.7514 - val_accuracy: 0.7633 - val_auc: 0.7838 - val_loss: 0.5269 - val_precision: 0.6937 - val_recall: 0.8867\n",
      "Epoch 123/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7471 - auc: 0.8045 - loss: 0.5346 - precision: 0.7199 - recall: 0.7532 - val_accuracy: 0.7631 - val_auc: 0.7841 - val_loss: 0.5264 - val_precision: 0.6936 - val_recall: 0.8860\n",
      "Epoch 124/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7461 - auc: 0.8054 - loss: 0.5342 - precision: 0.7188 - recall: 0.7522 - val_accuracy: 0.7637 - val_auc: 0.7851 - val_loss: 0.5256 - val_precision: 0.6940 - val_recall: 0.8872\n",
      "Epoch 125/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8051 - loss: 0.5347 - precision: 0.7206 - recall: 0.7541 - val_accuracy: 0.7636 - val_auc: 0.7841 - val_loss: 0.5272 - val_precision: 0.6939 - val_recall: 0.8872\n",
      "Epoch 126/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7453 - auc: 0.8057 - loss: 0.5339 - precision: 0.7182 - recall: 0.7510 - val_accuracy: 0.7633 - val_auc: 0.7842 - val_loss: 0.5265 - val_precision: 0.6937 - val_recall: 0.8867\n",
      "Epoch 127/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7465 - auc: 0.8065 - loss: 0.5330 - precision: 0.7197 - recall: 0.7514 - val_accuracy: 0.7638 - val_auc: 0.7830 - val_loss: 0.5266 - val_precision: 0.6940 - val_recall: 0.8879\n",
      "Epoch 128/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7474 - auc: 0.8050 - loss: 0.5345 - precision: 0.7203 - recall: 0.7533 - val_accuracy: 0.7637 - val_auc: 0.7830 - val_loss: 0.5275 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 129/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7466 - auc: 0.8056 - loss: 0.5335 - precision: 0.7199 - recall: 0.7514 - val_accuracy: 0.7634 - val_auc: 0.7837 - val_loss: 0.5292 - val_precision: 0.6935 - val_recall: 0.8876\n",
      "Epoch 130/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7471 - auc: 0.8053 - loss: 0.5341 - precision: 0.7199 - recall: 0.7531 - val_accuracy: 0.7636 - val_auc: 0.7844 - val_loss: 0.5267 - val_precision: 0.6937 - val_recall: 0.8879\n",
      "Epoch 131/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7470 - auc: 0.8058 - loss: 0.5339 - precision: 0.7196 - recall: 0.7534 - val_accuracy: 0.7633 - val_auc: 0.7835 - val_loss: 0.5286 - val_precision: 0.6935 - val_recall: 0.8874\n",
      "Epoch 132/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8061 - loss: 0.5333 - precision: 0.7216 - recall: 0.7519 - val_accuracy: 0.7634 - val_auc: 0.7836 - val_loss: 0.5285 - val_precision: 0.6936 - val_recall: 0.8874\n",
      "Epoch 133/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7466 - auc: 0.8060 - loss: 0.5330 - precision: 0.7190 - recall: 0.7534 - val_accuracy: 0.7635 - val_auc: 0.7838 - val_loss: 0.5275 - val_precision: 0.6937 - val_recall: 0.8874\n",
      "Epoch 134/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7481 - auc: 0.8066 - loss: 0.5327 - precision: 0.7212 - recall: 0.7536 - val_accuracy: 0.7637 - val_auc: 0.7850 - val_loss: 0.5251 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 135/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7491 - auc: 0.8059 - loss: 0.5336 - precision: 0.7215 - recall: 0.7563 - val_accuracy: 0.7637 - val_auc: 0.7835 - val_loss: 0.5264 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 136/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7498 - auc: 0.8069 - loss: 0.5322 - precision: 0.7231 - recall: 0.7550 - val_accuracy: 0.7633 - val_auc: 0.7839 - val_loss: 0.5294 - val_precision: 0.6935 - val_recall: 0.8874\n",
      "Epoch 137/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7469 - auc: 0.8058 - loss: 0.5337 - precision: 0.7204 - recall: 0.7512 - val_accuracy: 0.7637 - val_auc: 0.7828 - val_loss: 0.5321 - val_precision: 0.6938 - val_recall: 0.8881\n",
      "Epoch 138/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7489 - auc: 0.8074 - loss: 0.5320 - precision: 0.7226 - recall: 0.7529 - val_accuracy: 0.7635 - val_auc: 0.7832 - val_loss: 0.5295 - val_precision: 0.6939 - val_recall: 0.8867\n",
      "Epoch 139/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7487 - auc: 0.8061 - loss: 0.5329 - precision: 0.7205 - recall: 0.7574 - val_accuracy: 0.7638 - val_auc: 0.7834 - val_loss: 0.5270 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 140/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7484 - auc: 0.8046 - loss: 0.5344 - precision: 0.7198 - recall: 0.7578 - val_accuracy: 0.7637 - val_auc: 0.7828 - val_loss: 0.5279 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 141/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7483 - auc: 0.8070 - loss: 0.5321 - precision: 0.7206 - recall: 0.7556 - val_accuracy: 0.7635 - val_auc: 0.7830 - val_loss: 0.5305 - val_precision: 0.6936 - val_recall: 0.8879\n",
      "Epoch 142/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7472 - auc: 0.8069 - loss: 0.5324 - precision: 0.7203 - recall: 0.7526 - val_accuracy: 0.7637 - val_auc: 0.7822 - val_loss: 0.5271 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 143/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7469 - auc: 0.8048 - loss: 0.5344 - precision: 0.7199 - recall: 0.7525 - val_accuracy: 0.7637 - val_auc: 0.7826 - val_loss: 0.5277 - val_precision: 0.6939 - val_recall: 0.8876\n",
      "Epoch 144/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7476 - auc: 0.8074 - loss: 0.5319 - precision: 0.7204 - recall: 0.7536 - val_accuracy: 0.7629 - val_auc: 0.7830 - val_loss: 0.5278 - val_precision: 0.6937 - val_recall: 0.8853\n",
      "Epoch 145/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7499 - auc: 0.8086 - loss: 0.5303 - precision: 0.7234 - recall: 0.7549 - val_accuracy: 0.7634 - val_auc: 0.7828 - val_loss: 0.5279 - val_precision: 0.6939 - val_recall: 0.8865\n",
      "Epoch 146/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7467 - auc: 0.8062 - loss: 0.5328 - precision: 0.7198 - recall: 0.7520 - val_accuracy: 0.7638 - val_auc: 0.7830 - val_loss: 0.5283 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 147/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7499 - auc: 0.8081 - loss: 0.5308 - precision: 0.7232 - recall: 0.7554 - val_accuracy: 0.7633 - val_auc: 0.7831 - val_loss: 0.5289 - val_precision: 0.6937 - val_recall: 0.8865\n",
      "Epoch 148/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7467 - auc: 0.8059 - loss: 0.5333 - precision: 0.7191 - recall: 0.7536 - val_accuracy: 0.7636 - val_auc: 0.7841 - val_loss: 0.5270 - val_precision: 0.6940 - val_recall: 0.8869\n",
      "Epoch 149/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7473 - auc: 0.8076 - loss: 0.5322 - precision: 0.7211 - recall: 0.7508 - val_accuracy: 0.7634 - val_auc: 0.7829 - val_loss: 0.5306 - val_precision: 0.6939 - val_recall: 0.8865\n",
      "Epoch 150/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7476 - auc: 0.8066 - loss: 0.5333 - precision: 0.7212 - recall: 0.7519 - val_accuracy: 0.7627 - val_auc: 0.7836 - val_loss: 0.5282 - val_precision: 0.6936 - val_recall: 0.8848\n",
      "Epoch 151/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7467 - auc: 0.8056 - loss: 0.5339 - precision: 0.7193 - recall: 0.7532 - val_accuracy: 0.7640 - val_auc: 0.7835 - val_loss: 0.5271 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 152/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8071 - loss: 0.5321 - precision: 0.7205 - recall: 0.7545 - val_accuracy: 0.7636 - val_auc: 0.7834 - val_loss: 0.5285 - val_precision: 0.6938 - val_recall: 0.8874\n",
      "Epoch 153/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7471 - auc: 0.8071 - loss: 0.5322 - precision: 0.7201 - recall: 0.7526 - val_accuracy: 0.7636 - val_auc: 0.7827 - val_loss: 0.5280 - val_precision: 0.6939 - val_recall: 0.8872\n",
      "Epoch 154/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7489 - auc: 0.8072 - loss: 0.5323 - precision: 0.7220 - recall: 0.7546 - val_accuracy: 0.7634 - val_auc: 0.7825 - val_loss: 0.5285 - val_precision: 0.6938 - val_recall: 0.8867\n",
      "Epoch 155/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7494 - auc: 0.8065 - loss: 0.5329 - precision: 0.7218 - recall: 0.7566 - val_accuracy: 0.7636 - val_auc: 0.7831 - val_loss: 0.5286 - val_precision: 0.6939 - val_recall: 0.8872\n",
      "Epoch 156/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7475 - auc: 0.8076 - loss: 0.5312 - precision: 0.7204 - recall: 0.7536 - val_accuracy: 0.7640 - val_auc: 0.7824 - val_loss: 0.5271 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 157/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7485 - auc: 0.8078 - loss: 0.5319 - precision: 0.7219 - recall: 0.7533 - val_accuracy: 0.7631 - val_auc: 0.7839 - val_loss: 0.5279 - val_precision: 0.6936 - val_recall: 0.8860\n",
      "Epoch 158/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7484 - auc: 0.8084 - loss: 0.5306 - precision: 0.7211 - recall: 0.7546 - val_accuracy: 0.7634 - val_auc: 0.7826 - val_loss: 0.5295 - val_precision: 0.6939 - val_recall: 0.8865\n",
      "Epoch 159/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7480 - auc: 0.8083 - loss: 0.5311 - precision: 0.7207 - recall: 0.7544 - val_accuracy: 0.7640 - val_auc: 0.7824 - val_loss: 0.5296 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 160/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7444 - auc: 0.8062 - loss: 0.5329 - precision: 0.7174 - recall: 0.7498 - val_accuracy: 0.7642 - val_auc: 0.7828 - val_loss: 0.5278 - val_precision: 0.6942 - val_recall: 0.8884\n",
      "Epoch 161/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8067 - loss: 0.5327 - precision: 0.7216 - recall: 0.7519 - val_accuracy: 0.7640 - val_auc: 0.7829 - val_loss: 0.5296 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 162/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7475 - auc: 0.8069 - loss: 0.5329 - precision: 0.7212 - recall: 0.7516 - val_accuracy: 0.7638 - val_auc: 0.7831 - val_loss: 0.5270 - val_precision: 0.6941 - val_recall: 0.8874\n",
      "Epoch 163/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7461 - auc: 0.8070 - loss: 0.5326 - precision: 0.7197 - recall: 0.7501 - val_accuracy: 0.7637 - val_auc: 0.7829 - val_loss: 0.5279 - val_precision: 0.6940 - val_recall: 0.8874\n",
      "Epoch 164/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7474 - auc: 0.8064 - loss: 0.5323 - precision: 0.7192 - recall: 0.7559 - val_accuracy: 0.7642 - val_auc: 0.7831 - val_loss: 0.5271 - val_precision: 0.6943 - val_recall: 0.8881\n",
      "Epoch 165/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7488 - auc: 0.8069 - loss: 0.5316 - precision: 0.7209 - recall: 0.7569 - val_accuracy: 0.7637 - val_auc: 0.7833 - val_loss: 0.5272 - val_precision: 0.6940 - val_recall: 0.8872\n",
      "Epoch 166/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7481 - auc: 0.8079 - loss: 0.5316 - precision: 0.7218 - recall: 0.7522 - val_accuracy: 0.7642 - val_auc: 0.7830 - val_loss: 0.5274 - val_precision: 0.6942 - val_recall: 0.8884\n",
      "Epoch 167/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7492 - auc: 0.8076 - loss: 0.5313 - precision: 0.7220 - recall: 0.7555 - val_accuracy: 0.7641 - val_auc: 0.7835 - val_loss: 0.5283 - val_precision: 0.6942 - val_recall: 0.8879\n",
      "Epoch 168/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8067 - loss: 0.5321 - precision: 0.7205 - recall: 0.7545 - val_accuracy: 0.7640 - val_auc: 0.7821 - val_loss: 0.5268 - val_precision: 0.6941 - val_recall: 0.8879\n",
      "Epoch 169/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7494 - auc: 0.8084 - loss: 0.5315 - precision: 0.7237 - recall: 0.7522 - val_accuracy: 0.7641 - val_auc: 0.7826 - val_loss: 0.5284 - val_precision: 0.6943 - val_recall: 0.8876\n",
      "Epoch 170/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7482 - auc: 0.8070 - loss: 0.5324 - precision: 0.7209 - recall: 0.7547 - val_accuracy: 0.7638 - val_auc: 0.7826 - val_loss: 0.5283 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 171/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7487 - auc: 0.8085 - loss: 0.5302 - precision: 0.7211 - recall: 0.7560 - val_accuracy: 0.7640 - val_auc: 0.7828 - val_loss: 0.5270 - val_precision: 0.6941 - val_recall: 0.8879\n",
      "Epoch 172/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.7484 - auc: 0.8080 - loss: 0.5316 - precision: 0.7215 - recall: 0.7541 - val_accuracy: 0.7638 - val_auc: 0.7831 - val_loss: 0.5292 - val_precision: 0.6942 - val_recall: 0.8872\n",
      "Epoch 173/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7498 - auc: 0.8078 - loss: 0.5317 - precision: 0.7237 - recall: 0.7538 - val_accuracy: 0.7640 - val_auc: 0.7827 - val_loss: 0.5270 - val_precision: 0.6941 - val_recall: 0.8879\n",
      "Epoch 174/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7489 - auc: 0.8092 - loss: 0.5302 - precision: 0.7224 - recall: 0.7534 - val_accuracy: 0.7640 - val_auc: 0.7828 - val_loss: 0.5282 - val_precision: 0.6942 - val_recall: 0.8876\n",
      "Epoch 175/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7496 - auc: 0.8078 - loss: 0.5316 - precision: 0.7227 - recall: 0.7553 - val_accuracy: 0.7636 - val_auc: 0.7829 - val_loss: 0.5281 - val_precision: 0.6940 - val_recall: 0.8869\n",
      "Epoch 176/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7498 - auc: 0.8089 - loss: 0.5305 - precision: 0.7238 - recall: 0.7536 - val_accuracy: 0.7634 - val_auc: 0.7822 - val_loss: 0.5306 - val_precision: 0.6938 - val_recall: 0.8867\n",
      "Epoch 177/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7482 - auc: 0.8078 - loss: 0.5311 - precision: 0.7220 - recall: 0.7520 - val_accuracy: 0.7641 - val_auc: 0.7826 - val_loss: 0.5289 - val_precision: 0.6944 - val_recall: 0.8872\n",
      "Epoch 178/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7491 - auc: 0.8107 - loss: 0.5283 - precision: 0.7215 - recall: 0.7561 - val_accuracy: 0.7637 - val_auc: 0.7824 - val_loss: 0.5274 - val_precision: 0.6941 - val_recall: 0.8869\n",
      "Epoch 179/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7498 - auc: 0.8092 - loss: 0.5298 - precision: 0.7230 - recall: 0.7554 - val_accuracy: 0.7636 - val_auc: 0.7828 - val_loss: 0.5266 - val_precision: 0.6940 - val_recall: 0.8869\n",
      "Epoch 180/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7488 - auc: 0.8095 - loss: 0.5303 - precision: 0.7234 - recall: 0.7510 - val_accuracy: 0.7638 - val_auc: 0.7830 - val_loss: 0.5291 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 181/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7473 - auc: 0.8086 - loss: 0.5309 - precision: 0.7202 - recall: 0.7533 - val_accuracy: 0.7638 - val_auc: 0.7833 - val_loss: 0.5278 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 182/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7490 - auc: 0.8086 - loss: 0.5309 - precision: 0.7233 - recall: 0.7519 - val_accuracy: 0.7641 - val_auc: 0.7833 - val_loss: 0.5274 - val_precision: 0.6942 - val_recall: 0.8879\n",
      "Epoch 183/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7470 - auc: 0.8069 - loss: 0.5330 - precision: 0.7211 - recall: 0.7500 - val_accuracy: 0.7631 - val_auc: 0.7841 - val_loss: 0.5271 - val_precision: 0.6937 - val_recall: 0.8857\n",
      "Epoch 184/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7481 - auc: 0.8083 - loss: 0.5315 - precision: 0.7218 - recall: 0.7521 - val_accuracy: 0.7640 - val_auc: 0.7844 - val_loss: 0.5265 - val_precision: 0.6941 - val_recall: 0.8879\n",
      "Epoch 185/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7480 - auc: 0.8081 - loss: 0.5311 - precision: 0.7213 - recall: 0.7532 - val_accuracy: 0.7637 - val_auc: 0.7837 - val_loss: 0.5266 - val_precision: 0.6942 - val_recall: 0.8867\n",
      "Epoch 186/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7506 - auc: 0.8091 - loss: 0.5303 - precision: 0.7241 - recall: 0.7554 - val_accuracy: 0.7637 - val_auc: 0.7827 - val_loss: 0.5296 - val_precision: 0.6940 - val_recall: 0.8872\n",
      "Epoch 187/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7478 - auc: 0.8089 - loss: 0.5307 - precision: 0.7214 - recall: 0.7520 - val_accuracy: 0.7641 - val_auc: 0.7826 - val_loss: 0.5290 - val_precision: 0.6944 - val_recall: 0.8874\n",
      "Epoch 188/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7474 - auc: 0.8080 - loss: 0.5315 - precision: 0.7205 - recall: 0.7529 - val_accuracy: 0.7631 - val_auc: 0.7827 - val_loss: 0.5316 - val_precision: 0.6939 - val_recall: 0.8850\n",
      "Epoch 189/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7500 - auc: 0.8084 - loss: 0.5310 - precision: 0.7242 - recall: 0.7531 - val_accuracy: 0.7634 - val_auc: 0.7840 - val_loss: 0.5298 - val_precision: 0.6939 - val_recall: 0.8865\n",
      "Epoch 190/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7494 - auc: 0.8085 - loss: 0.5312 - precision: 0.7234 - recall: 0.7531 - val_accuracy: 0.7637 - val_auc: 0.7826 - val_loss: 0.5274 - val_precision: 0.6940 - val_recall: 0.8872\n",
      "Epoch 191/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7481 - auc: 0.8099 - loss: 0.5298 - precision: 0.7214 - recall: 0.7532 - val_accuracy: 0.7638 - val_auc: 0.7835 - val_loss: 0.5288 - val_precision: 0.6941 - val_recall: 0.8874\n",
      "Epoch 192/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7488 - auc: 0.8095 - loss: 0.5301 - precision: 0.7230 - recall: 0.7518 - val_accuracy: 0.7633 - val_auc: 0.7834 - val_loss: 0.5287 - val_precision: 0.6940 - val_recall: 0.8855\n",
      "Epoch 193/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7470 - auc: 0.8090 - loss: 0.5304 - precision: 0.7203 - recall: 0.7516 - val_accuracy: 0.7641 - val_auc: 0.7838 - val_loss: 0.5283 - val_precision: 0.6943 - val_recall: 0.8876\n",
      "Epoch 194/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7472 - auc: 0.8092 - loss: 0.5305 - precision: 0.7218 - recall: 0.7490 - val_accuracy: 0.7640 - val_auc: 0.7835 - val_loss: 0.5291 - val_precision: 0.6942 - val_recall: 0.8874\n",
      "Epoch 195/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7497 - auc: 0.8099 - loss: 0.5296 - precision: 0.7227 - recall: 0.7557 - val_accuracy: 0.7642 - val_auc: 0.7834 - val_loss: 0.5291 - val_precision: 0.6944 - val_recall: 0.8876\n",
      "Epoch 196/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7508 - auc: 0.8096 - loss: 0.5295 - precision: 0.7237 - recall: 0.7570 - val_accuracy: 0.7635 - val_auc: 0.7841 - val_loss: 0.5276 - val_precision: 0.6939 - val_recall: 0.8867\n",
      "Epoch 197/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7476 - auc: 0.8080 - loss: 0.5315 - precision: 0.7207 - recall: 0.7531 - val_accuracy: 0.7638 - val_auc: 0.7839 - val_loss: 0.5273 - val_precision: 0.6943 - val_recall: 0.8867\n",
      "Epoch 198/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7474 - auc: 0.8088 - loss: 0.5306 - precision: 0.7210 - recall: 0.7516 - val_accuracy: 0.7634 - val_auc: 0.7842 - val_loss: 0.5260 - val_precision: 0.6939 - val_recall: 0.8865\n",
      "Epoch 199/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7502 - auc: 0.8106 - loss: 0.5285 - precision: 0.7232 - recall: 0.7560 - val_accuracy: 0.7638 - val_auc: 0.7832 - val_loss: 0.5272 - val_precision: 0.6940 - val_recall: 0.8876\n",
      "Epoch 200/200\n",
      "\u001b[1m8960/8960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7479 - auc: 0.8085 - loss: 0.5307 - precision: 0.7211 - recall: 0.7532 - val_accuracy: 0.7636 - val_auc: 0.7835 - val_loss: 0.5269 - val_precision: 0.6940 - val_recall: 0.8869\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 1000, restore_best_weights = True)\n",
    "history = model.fit(\n",
    "    X_train , y_train ,\n",
    "    epochs = 200,\n",
    "    batch_size = 4,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65490eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7758 - auc: 0.7931 - loss: 0.5044 - precision: 0.7035 - recall: 0.9015\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, auc=model.evaluate(\n",
    "    X_test,y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3d2b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss \t\t : 0.5043652057647705\n",
      "accuracy \t : 0.7758035659790039\n",
      "precision \t : 0.7034944295883179\n",
      "recall \t\t : 0.9014862775802612\n",
      "auc \t\t : 0.7931306958198547\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss \\t\\t : {loss}\")\n",
    "print(f\"accuracy \\t : {accuracy}\")\n",
    "print(f\"precision \\t : {precision}\")\n",
    "print(f\"recall \\t\\t : {recall}\")\n",
    "print(f\"auc \\t\\t : {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924a789",
   "metadata": {},
   "source": [
    "Certainly! Here is a table summarizing the five evaluation metrics for binary classification models, their purpose, and what their values mean.\n",
    "\n",
    "| Metric | Purpose / What It Measures | Calculation | Interpretation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Loss** (Binary Cross-Entropy) | Measures the **error** between the predicted probabilities and the true labels. The value the model tries to minimize. | Based on the natural logarithm of predicted probabilities. | **Lower is better** (closer to $0.0$). A high value means the model is confidently wrong often. |\n",
    "| **Accuracy** | Measures the proportion of **total predictions** that were correct (both positive and negative). | $\\frac{\\text{TP} + \\text{TN}}{\\text{Total Samples}}$ | General measure of correctness. Can be misleading with imbalanced data. |\n",
    "| **Precision** | Measures the confidence of **positive predictions**. \"Of all predicted positive cases, how many were actually positive?\" | $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$ | **Higher is better.** Prioritized when **False Alarms** (False Positives) are costly. |\n",
    "| **Recall** | Measures the model's ability to **find all positive cases**. \"Of all actual positive cases, how many were correctly identified?\" | $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$ | **Higher is better.** Prioritized when **Missing a case** (False Negatives) is costly. |\n",
    "| **AUC** (Area Under the ROC Curve) | Measures the **overall model quality** across all possible thresholds, particularly useful for imbalanced data. | Probability of correctly ranking a random positive case higher than a random negative case. | Ranges from $0.5$ (random) to $1.0$ (perfect). **Higher is better.** |\n",
    "\n",
    "*(Note: TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1931c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7084075 ],\n",
       "       [0.74745226],\n",
       "       [0.71546894],\n",
       "       ...,\n",
       "       [0.718054  ],\n",
       "       [0.74230975],\n",
       "       [0.7411003 ]], shape=(11200, 1), dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a7c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_prob >= 0.5).astype(int) # to addjest to the recall and the precision can adjest thie threshold. but adjestion this can get tradeoffs. edit with caution.\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a105bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3958, 1994],\n",
       "       [ 517, 4731]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefa0c0",
   "metadata": {},
   "source": [
    "The code you provided uses the `confusion_matrix` function from the `sklearn.metrics` module to generate a **Confusion Matrix**.\n",
    "\n",
    "This matrix is a table that summarizes the performance of your classification model by comparing the model's binary predictions (`y_pred`) against the actual true labels (`y_test`). It is the foundation for calculating metrics like Precision and Recall.\n",
    "\n",
    "***\n",
    "\n",
    "## What the Confusion Matrix Does\n",
    "\n",
    "The Confusion Matrix breaks down your model's predictions into four distinct categories:\n",
    "\n",
    "| | **Predicted: No Churn (0)** | **Predicted: Churn (1)** |\n",
    "| :--- | :--- | :--- |\n",
    "| **Actual: No Churn (0)** | **True Negative (TN)** | **False Positive (FP)** |\n",
    "| **Actual: Churn (1)** | **False Negative (FN)** | **True Positive (TP)** |\n",
    "\n",
    "### Explanation of the Four Components:\n",
    "\n",
    "1.  **True Positive (TP):** The model correctly predicted Churn (1) when the customer **actually churned** (1). (Good)\n",
    "2.  **True Negative (TN):** The model correctly predicted No Churn (0) when the customer **actually stayed** (0). (Good)\n",
    "3.  **False Positive (FP):** The model predicted Churn (1) when the customer **actually stayed** (0). This is a **False Alarm**. (Bad)\n",
    "4.  **False Negative (FN):** The model predicted No Churn (0) when the customer **actually churned** (1). This is a **Missed Opportunity**. (Bad)\n",
    "\n",
    "## Example Output\n",
    "\n",
    "When you run `confusion_matrix(y_test, y_pred)`, the output (using scikit-learn's standard format) will look like this, where the labels are organized as `[TN, FP], [FN, TP]`:\n",
    "\n",
    "$$\\begin{bmatrix} TN & FP \\\\ FN & TP \\end{bmatrix}$$\n",
    "\n",
    "For instance, if the output is:\n",
    "\n",
    "$$\\begin{bmatrix} 900 & 100 \\\\ 50 & 150 \\end{bmatrix}$$\n",
    "\n",
    "It means:\n",
    "\n",
    "* **900** customers were correctly predicted to stay (TN).\n",
    "* **100** customers were falsely predicted to churn (FP - False Alarms).\n",
    "* **50** customers were missed (FN - Missed Churners).\n",
    "* **150** customers were correctly predicted to churn (TP).\n",
    "\n",
    "This matrix gives you the raw counts needed to calculate all your key metrics: Precision, Recall, and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fc848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa409dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a530f0d",
   "metadata": {},
   "source": [
    "`Saving the model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d423bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as telco_churn_prediction_model_V1.0.keras\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'telco_churn_prediction_model_V1.0.keras'\n",
    "# Save the entire model\n",
    "model.save(model_filename) \n",
    "\n",
    "print(f\"Model saved successfully as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_TensorFlow_cpu_1 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
