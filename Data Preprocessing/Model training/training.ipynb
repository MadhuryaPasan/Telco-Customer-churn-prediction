{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7425aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a9ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SeniorCitizen",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tenure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PhoneService",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaperlessBilling",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MonthlyCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TotalCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Churn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_Month-to-Month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_One year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contract_Two year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Bank transfer (automatic)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Credit card (automatic)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Electronic check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Mailed check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PaymentMethod_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender_Female",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partner_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dependents_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MultipleLines_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_DSL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_Fiber optic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InternetService_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineSecurity_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OnlineBackup_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeviceProtection_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TechSupport_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingTV_Yes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_Unknown",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StreamingMovies_Yes",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9012fc5a-464d-4763-8737-772634a35640",
       "rows": [
        [
         "0",
         "0",
         "-0.2441995978989742",
         "1",
         "1",
         "0.0210828941063727",
         "0.0013911071014704",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "1",
         "1",
         "-0.3067479778476306",
         "1",
         "0",
         "0.053733035491338",
         "0.0026127642849414",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2",
         "0",
         "-0.7445866374882254",
         "1",
         "0",
         "0.0043933943864432",
         "0.000400889719128",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "3",
         "0",
         "1.06931638102281",
         "1",
         "1",
         "0.0205969887364435",
         "0.0028858231033112",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "0",
         "-0.6194898775909126",
         "1",
         "0",
         "0.0414436788435452",
         "0.0015349967870163",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 47,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Contract_Month-to-Month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection_Yes</th>\n",
       "      <th>TechSupport_No</th>\n",
       "      <th>TechSupport_Unknown</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_No</th>\n",
       "      <th>StreamingTV_Unknown</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <th>StreamingMovies_Unknown</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.244200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021083</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.306748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053733</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.744587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.069316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.619490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041444</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen    tenure  PhoneService  PaperlessBilling  MonthlyCharges  \\\n",
       "0              0 -0.244200             1                 1        0.021083   \n",
       "1              1 -0.306748             1                 0        0.053733   \n",
       "2              0 -0.744587             1                 0        0.004393   \n",
       "3              0  1.069316             1                 1        0.020597   \n",
       "4              0 -0.619490             1                 0        0.041444   \n",
       "\n",
       "   TotalCharges  Churn  Contract_Month-to-Month  Contract_One year  \\\n",
       "0      0.001391      0                        1                  0   \n",
       "1      0.002613      0                        0                  0   \n",
       "2      0.000401      0                        0                  1   \n",
       "3      0.002886      0                        0                  0   \n",
       "4      0.001535      0                        1                  0   \n",
       "\n",
       "   Contract_Two year  ...  DeviceProtection_Yes  TechSupport_No  \\\n",
       "0                  0  ...                     0               1   \n",
       "1                  1  ...                     0               1   \n",
       "2                  0  ...                     0               1   \n",
       "3                  1  ...                     0               1   \n",
       "4                  0  ...                     1               1   \n",
       "\n",
       "   TechSupport_Unknown  TechSupport_Yes  StreamingTV_No  StreamingTV_Unknown  \\\n",
       "0                    0                0               0                    0   \n",
       "1                    0                0               1                    0   \n",
       "2                    0                0               1                    0   \n",
       "3                    0                0               1                    0   \n",
       "4                    0                0               1                    0   \n",
       "\n",
       "   StreamingTV_Yes  StreamingMovies_No  StreamingMovies_Unknown  \\\n",
       "0                1                   0                        0   \n",
       "1                0                   1                        0   \n",
       "2                0                   1                        0   \n",
       "3                0                   1                        0   \n",
       "4                0                   1                        0   \n",
       "\n",
       "   StreamingMovies_Yes  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('04.reduced_telco_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602b0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign X (all columns except 'Churn')\n",
    "# X = data.drop(columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "691163e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign Y (only 'Churn')\n",
    "# Y = data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30f02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"X shape:\", X.shape)  \n",
    "# X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c513df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Y shape:\", Y.shape) \n",
    "# Y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce463afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train-test split (80% train, 20% test)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d72567ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train-test split done!\")\n",
    "# print(\"Train size:\", X_train.shape, Y_train.shape)\n",
    "# print(\"Test size:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fa8ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save them to train_test_split_dataset folder\n",
    "# X_train.to_csv(\"../Train_test_dataset/X_train.csv\", index=False)\n",
    "# X_test.to_csv(\"../Train_test_dataset/X_test.csv\", index=False)\n",
    "# Y_train.to_csv(\"../Train_test_dataset/Y_train.csv\", index=False)\n",
    "# Y_test.to_csv(\"../Train_test_dataset/Y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ff638c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   SeniorCitizen                            56000 non-null  int64  \n",
      " 1   tenure                                   56000 non-null  float64\n",
      " 2   PhoneService                             56000 non-null  int64  \n",
      " 3   PaperlessBilling                         56000 non-null  int64  \n",
      " 4   MonthlyCharges                           56000 non-null  float64\n",
      " 5   TotalCharges                             56000 non-null  float64\n",
      " 6   Churn                                    56000 non-null  int64  \n",
      " 7   Contract_Month-to-Month                  56000 non-null  int64  \n",
      " 8   Contract_One year                        56000 non-null  int64  \n",
      " 9   Contract_Two year                        56000 non-null  int64  \n",
      " 10  PaymentMethod_Bank transfer (automatic)  56000 non-null  int64  \n",
      " 11  PaymentMethod_Credit card (automatic)    56000 non-null  int64  \n",
      " 12  PaymentMethod_Electronic check           56000 non-null  int64  \n",
      " 13  PaymentMethod_Mailed check               56000 non-null  int64  \n",
      " 14  PaymentMethod_Unknown                    56000 non-null  int64  \n",
      " 15  gender_Female                            56000 non-null  int64  \n",
      " 16  gender_Unknown                           56000 non-null  int64  \n",
      " 17  Partner_No                               56000 non-null  int64  \n",
      " 18  Partner_Unknown                          56000 non-null  int64  \n",
      " 19  Partner_Yes                              56000 non-null  int64  \n",
      " 20  Dependents_No                            56000 non-null  int64  \n",
      " 21  Dependents_Unknown                       56000 non-null  int64  \n",
      " 22  Dependents_Yes                           56000 non-null  int64  \n",
      " 23  MultipleLines_No                         56000 non-null  int64  \n",
      " 24  MultipleLines_Unknown                    56000 non-null  int64  \n",
      " 25  MultipleLines_Yes                        56000 non-null  int64  \n",
      " 26  InternetService_DSL                      56000 non-null  int64  \n",
      " 27  InternetService_Fiber optic              56000 non-null  int64  \n",
      " 28  InternetService_No                       56000 non-null  int64  \n",
      " 29  OnlineSecurity_No                        56000 non-null  int64  \n",
      " 30  OnlineSecurity_Unknown                   56000 non-null  int64  \n",
      " 31  OnlineSecurity_Yes                       56000 non-null  int64  \n",
      " 32  OnlineBackup_No                          56000 non-null  int64  \n",
      " 33  OnlineBackup_Unknown                     56000 non-null  int64  \n",
      " 34  OnlineBackup_Yes                         56000 non-null  int64  \n",
      " 35  DeviceProtection_No                      56000 non-null  int64  \n",
      " 36  DeviceProtection_Unknown                 56000 non-null  int64  \n",
      " 37  DeviceProtection_Yes                     56000 non-null  int64  \n",
      " 38  TechSupport_No                           56000 non-null  int64  \n",
      " 39  TechSupport_Unknown                      56000 non-null  int64  \n",
      " 40  TechSupport_Yes                          56000 non-null  int64  \n",
      " 41  StreamingTV_No                           56000 non-null  int64  \n",
      " 42  StreamingTV_Unknown                      56000 non-null  int64  \n",
      " 43  StreamingTV_Yes                          56000 non-null  int64  \n",
      " 44  StreamingMovies_No                       56000 non-null  int64  \n",
      " 45  StreamingMovies_Unknown                  56000 non-null  int64  \n",
      " 46  StreamingMovies_Yes                      56000 non-null  int64  \n",
      "dtypes: float64(3), int64(44)\n",
      "memory usage: 20.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96fe6561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], shape=(56000,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,6].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0482eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.drop(data.columns[6], axis=1)\n",
    "X = tmp.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "041888b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.2441996 ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , -0.30674798,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.74458664,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.6940261 ,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.30674798,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        , -1.24497368,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ]], shape=(56000, 46))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc66c521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29762, 26238])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(y) # *output-> [0 count, 1 count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f955ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.8,\n",
    "    random_state= 42,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0eb9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5587839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.13186476, 1.        , 1.        , 0.00743705,\n",
       "       0.00176917, 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4055fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa4dec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7346055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b5b2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(64, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(16, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d626fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,081</span> (23.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,081\u001b[0m (23.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,857</span> (22.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,857\u001b[0m (22.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880099e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),  # Area Under the Curve (ROC)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37f87e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   SeniorCitizen                            56000 non-null  int64  \n",
      " 1   tenure                                   56000 non-null  float64\n",
      " 2   PhoneService                             56000 non-null  int64  \n",
      " 3   PaperlessBilling                         56000 non-null  int64  \n",
      " 4   MonthlyCharges                           56000 non-null  float64\n",
      " 5   TotalCharges                             56000 non-null  float64\n",
      " 6   Churn                                    56000 non-null  int64  \n",
      " 7   Contract_Month-to-Month                  56000 non-null  int64  \n",
      " 8   Contract_One year                        56000 non-null  int64  \n",
      " 9   Contract_Two year                        56000 non-null  int64  \n",
      " 10  PaymentMethod_Bank transfer (automatic)  56000 non-null  int64  \n",
      " 11  PaymentMethod_Credit card (automatic)    56000 non-null  int64  \n",
      " 12  PaymentMethod_Electronic check           56000 non-null  int64  \n",
      " 13  PaymentMethod_Mailed check               56000 non-null  int64  \n",
      " 14  PaymentMethod_Unknown                    56000 non-null  int64  \n",
      " 15  gender_Female                            56000 non-null  int64  \n",
      " 16  gender_Unknown                           56000 non-null  int64  \n",
      " 17  Partner_No                               56000 non-null  int64  \n",
      " 18  Partner_Unknown                          56000 non-null  int64  \n",
      " 19  Partner_Yes                              56000 non-null  int64  \n",
      " 20  Dependents_No                            56000 non-null  int64  \n",
      " 21  Dependents_Unknown                       56000 non-null  int64  \n",
      " 22  Dependents_Yes                           56000 non-null  int64  \n",
      " 23  MultipleLines_No                         56000 non-null  int64  \n",
      " 24  MultipleLines_Unknown                    56000 non-null  int64  \n",
      " 25  MultipleLines_Yes                        56000 non-null  int64  \n",
      " 26  InternetService_DSL                      56000 non-null  int64  \n",
      " 27  InternetService_Fiber optic              56000 non-null  int64  \n",
      " 28  InternetService_No                       56000 non-null  int64  \n",
      " 29  OnlineSecurity_No                        56000 non-null  int64  \n",
      " 30  OnlineSecurity_Unknown                   56000 non-null  int64  \n",
      " 31  OnlineSecurity_Yes                       56000 non-null  int64  \n",
      " 32  OnlineBackup_No                          56000 non-null  int64  \n",
      " 33  OnlineBackup_Unknown                     56000 non-null  int64  \n",
      " 34  OnlineBackup_Yes                         56000 non-null  int64  \n",
      " 35  DeviceProtection_No                      56000 non-null  int64  \n",
      " 36  DeviceProtection_Unknown                 56000 non-null  int64  \n",
      " 37  DeviceProtection_Yes                     56000 non-null  int64  \n",
      " 38  TechSupport_No                           56000 non-null  int64  \n",
      " 39  TechSupport_Unknown                      56000 non-null  int64  \n",
      " 40  TechSupport_Yes                          56000 non-null  int64  \n",
      " 41  StreamingTV_No                           56000 non-null  int64  \n",
      " 42  StreamingTV_Unknown                      56000 non-null  int64  \n",
      " 43  StreamingTV_Yes                          56000 non-null  int64  \n",
      " 44  StreamingMovies_No                       56000 non-null  int64  \n",
      " 45  StreamingMovies_Unknown                  56000 non-null  int64  \n",
      " 46  StreamingMovies_Yes                      56000 non-null  int64  \n",
      "dtypes: float64(3), int64(44)\n",
      "memory usage: 20.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f95dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6518 - auc_1: 0.6909 - loss: 0.6615 - precision_1: 0.6260 - recall_1: 0.6275 - val_accuracy: 0.7589 - val_auc_1: 0.7725 - val_loss: 0.5380 - val_precision_1: 0.6990 - val_recall_1: 0.8723\n",
      "Epoch 2/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7020 - auc_1: 0.7548 - loss: 0.5853 - precision_1: 0.6704 - recall_1: 0.7090 - val_accuracy: 0.7594 - val_auc_1: 0.7686 - val_loss: 0.5381 - val_precision_1: 0.6987 - val_recall_1: 0.8751\n",
      "Epoch 3/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7108 - auc_1: 0.7622 - loss: 0.5760 - precision_1: 0.6745 - recall_1: 0.7332 - val_accuracy: 0.7589 - val_auc_1: 0.7741 - val_loss: 0.5389 - val_precision_1: 0.6984 - val_recall_1: 0.8742\n",
      "Epoch 4/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7172 - auc_1: 0.7674 - loss: 0.5700 - precision_1: 0.6802 - recall_1: 0.7418 - val_accuracy: 0.7589 - val_auc_1: 0.7720 - val_loss: 0.5398 - val_precision_1: 0.6990 - val_recall_1: 0.8723\n",
      "Epoch 5/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7203 - auc_1: 0.7734 - loss: 0.5650 - precision_1: 0.6856 - recall_1: 0.7384 - val_accuracy: 0.7580 - val_auc_1: 0.7739 - val_loss: 0.5373 - val_precision_1: 0.6980 - val_recall_1: 0.8723\n",
      "Epoch 6/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7170 - auc_1: 0.7739 - loss: 0.5651 - precision_1: 0.6822 - recall_1: 0.7349 - val_accuracy: 0.7598 - val_auc_1: 0.7779 - val_loss: 0.5376 - val_precision_1: 0.6989 - val_recall_1: 0.8760\n",
      "Epoch 7/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7182 - auc_1: 0.7772 - loss: 0.5627 - precision_1: 0.6854 - recall_1: 0.7305 - val_accuracy: 0.7603 - val_auc_1: 0.7759 - val_loss: 0.5371 - val_precision_1: 0.6991 - val_recall_1: 0.8770\n",
      "Epoch 8/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7193 - auc_1: 0.7810 - loss: 0.5585 - precision_1: 0.6870 - recall_1: 0.7303 - val_accuracy: 0.7607 - val_auc_1: 0.7783 - val_loss: 0.5385 - val_precision_1: 0.6993 - val_recall_1: 0.8779\n",
      "Epoch 9/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7272 - auc_1: 0.7826 - loss: 0.5575 - precision_1: 0.6933 - recall_1: 0.7435 - val_accuracy: 0.7594 - val_auc_1: 0.7784 - val_loss: 0.5392 - val_precision_1: 0.6987 - val_recall_1: 0.8751\n",
      "Epoch 10/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7286 - auc_1: 0.7866 - loss: 0.5536 - precision_1: 0.6967 - recall_1: 0.7394 - val_accuracy: 0.7603 - val_auc_1: 0.7731 - val_loss: 0.5385 - val_precision_1: 0.6994 - val_recall_1: 0.8760\n",
      "Epoch 11/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7249 - auc_1: 0.7875 - loss: 0.5529 - precision_1: 0.6936 - recall_1: 0.7337 - val_accuracy: 0.7580 - val_auc_1: 0.7767 - val_loss: 0.5414 - val_precision_1: 0.6980 - val_recall_1: 0.8723\n",
      "Epoch 12/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7254 - auc_1: 0.7893 - loss: 0.5514 - precision_1: 0.6940 - recall_1: 0.7349 - val_accuracy: 0.7603 - val_auc_1: 0.7788 - val_loss: 0.5394 - val_precision_1: 0.6997 - val_recall_1: 0.8751\n",
      "Epoch 13/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7289 - auc_1: 0.7923 - loss: 0.5490 - precision_1: 0.7004 - recall_1: 0.7308 - val_accuracy: 0.7598 - val_auc_1: 0.7795 - val_loss: 0.5404 - val_precision_1: 0.6989 - val_recall_1: 0.8760\n",
      "Epoch 14/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7355 - auc_1: 0.7954 - loss: 0.5463 - precision_1: 0.7075 - recall_1: 0.7370 - val_accuracy: 0.7603 - val_auc_1: 0.7787 - val_loss: 0.5386 - val_precision_1: 0.6991 - val_recall_1: 0.8770\n",
      "Epoch 15/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7386 - auc_1: 0.7969 - loss: 0.5460 - precision_1: 0.7141 - recall_1: 0.7322 - val_accuracy: 0.7589 - val_auc_1: 0.7800 - val_loss: 0.5385 - val_precision_1: 0.6984 - val_recall_1: 0.8742\n",
      "Epoch 16/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7392 - auc_1: 0.8002 - loss: 0.5417 - precision_1: 0.7136 - recall_1: 0.7353 - val_accuracy: 0.7603 - val_auc_1: 0.7819 - val_loss: 0.5409 - val_precision_1: 0.6991 - val_recall_1: 0.8770\n",
      "Epoch 17/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7331 - auc_1: 0.7994 - loss: 0.5422 - precision_1: 0.7062 - recall_1: 0.7317 - val_accuracy: 0.7607 - val_auc_1: 0.7776 - val_loss: 0.5413 - val_precision_1: 0.6999 - val_recall_1: 0.8760\n",
      "Epoch 18/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7408 - auc_1: 0.8031 - loss: 0.5383 - precision_1: 0.7144 - recall_1: 0.7394 - val_accuracy: 0.7607 - val_auc_1: 0.7784 - val_loss: 0.5410 - val_precision_1: 0.6993 - val_recall_1: 0.8779\n",
      "Epoch 19/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7397 - auc_1: 0.8037 - loss: 0.5380 - precision_1: 0.7153 - recall_1: 0.7334 - val_accuracy: 0.7598 - val_auc_1: 0.7788 - val_loss: 0.5438 - val_precision_1: 0.6992 - val_recall_1: 0.8751\n",
      "Epoch 20/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7371 - auc_1: 0.8041 - loss: 0.5375 - precision_1: 0.7093 - recall_1: 0.7382 - val_accuracy: 0.7598 - val_auc_1: 0.7816 - val_loss: 0.5403 - val_precision_1: 0.6989 - val_recall_1: 0.8760\n",
      "Epoch 21/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7449 - auc_1: 0.8084 - loss: 0.5339 - precision_1: 0.7219 - recall_1: 0.7360 - val_accuracy: 0.7603 - val_auc_1: 0.7826 - val_loss: 0.5401 - val_precision_1: 0.6994 - val_recall_1: 0.8760\n",
      "Epoch 22/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7405 - auc_1: 0.8065 - loss: 0.5354 - precision_1: 0.7158 - recall_1: 0.7349 - val_accuracy: 0.7607 - val_auc_1: 0.7829 - val_loss: 0.5383 - val_precision_1: 0.6996 - val_recall_1: 0.8770\n",
      "Epoch 23/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7378 - auc_1: 0.8055 - loss: 0.5366 - precision_1: 0.7146 - recall_1: 0.7281 - val_accuracy: 0.7603 - val_auc_1: 0.7810 - val_loss: 0.5363 - val_precision_1: 0.6997 - val_recall_1: 0.8751\n",
      "Epoch 24/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7385 - auc_1: 0.8084 - loss: 0.5327 - precision_1: 0.7142 - recall_1: 0.7315 - val_accuracy: 0.7607 - val_auc_1: 0.7822 - val_loss: 0.5388 - val_precision_1: 0.6996 - val_recall_1: 0.8770\n",
      "Epoch 25/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7482 - auc_1: 0.8134 - loss: 0.5280 - precision_1: 0.7261 - recall_1: 0.7380 - val_accuracy: 0.7603 - val_auc_1: 0.7810 - val_loss: 0.5445 - val_precision_1: 0.6994 - val_recall_1: 0.8760\n",
      "Epoch 26/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7435 - auc_1: 0.8132 - loss: 0.5281 - precision_1: 0.7210 - recall_1: 0.7334 - val_accuracy: 0.7607 - val_auc_1: 0.7819 - val_loss: 0.5399 - val_precision_1: 0.7008 - val_recall_1: 0.8733\n",
      "Epoch 27/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7426 - auc_1: 0.8146 - loss: 0.5264 - precision_1: 0.7207 - recall_1: 0.7310 - val_accuracy: 0.7594 - val_auc_1: 0.7780 - val_loss: 0.5473 - val_precision_1: 0.6993 - val_recall_1: 0.8733\n",
      "Epoch 28/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7470 - auc_1: 0.8156 - loss: 0.5252 - precision_1: 0.7242 - recall_1: 0.7382 - val_accuracy: 0.7580 - val_auc_1: 0.7816 - val_loss: 0.5450 - val_precision_1: 0.6983 - val_recall_1: 0.8714\n",
      "Epoch 29/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7448 - auc_1: 0.8148 - loss: 0.5270 - precision_1: 0.7239 - recall_1: 0.7310 - val_accuracy: 0.7612 - val_auc_1: 0.7791 - val_loss: 0.5465 - val_precision_1: 0.7004 - val_recall_1: 0.8760\n",
      "Epoch 30/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7504 - auc_1: 0.8152 - loss: 0.5252 - precision_1: 0.7269 - recall_1: 0.7440 - val_accuracy: 0.7629 - val_auc_1: 0.7776 - val_loss: 0.5465 - val_precision_1: 0.7025 - val_recall_1: 0.8760\n",
      "Epoch 31/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7478 - auc_1: 0.8147 - loss: 0.5263 - precision_1: 0.7240 - recall_1: 0.7413 - val_accuracy: 0.7612 - val_auc_1: 0.7808 - val_loss: 0.5442 - val_precision_1: 0.7001 - val_recall_1: 0.8770\n",
      "Epoch 32/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7521 - auc_1: 0.8192 - loss: 0.5222 - precision_1: 0.7340 - recall_1: 0.7341 - val_accuracy: 0.7607 - val_auc_1: 0.7848 - val_loss: 0.5429 - val_precision_1: 0.7005 - val_recall_1: 0.8742\n",
      "Epoch 33/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7479 - auc_1: 0.8179 - loss: 0.5230 - precision_1: 0.7277 - recall_1: 0.7334 - val_accuracy: 0.7594 - val_auc_1: 0.7835 - val_loss: 0.5436 - val_precision_1: 0.7001 - val_recall_1: 0.8705\n",
      "Epoch 34/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7472 - auc_1: 0.8167 - loss: 0.5246 - precision_1: 0.7271 - recall_1: 0.7325 - val_accuracy: 0.7607 - val_auc_1: 0.7834 - val_loss: 0.5413 - val_precision_1: 0.7005 - val_recall_1: 0.8742\n",
      "Epoch 35/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7556 - auc_1: 0.8211 - loss: 0.5197 - precision_1: 0.7359 - recall_1: 0.7416 - val_accuracy: 0.7598 - val_auc_1: 0.7800 - val_loss: 0.5443 - val_precision_1: 0.7016 - val_recall_1: 0.8677\n",
      "Epoch 36/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7544 - auc_1: 0.8183 - loss: 0.5227 - precision_1: 0.7359 - recall_1: 0.7375 - val_accuracy: 0.7612 - val_auc_1: 0.7802 - val_loss: 0.5446 - val_precision_1: 0.7013 - val_recall_1: 0.8733\n",
      "Epoch 37/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7565 - auc_1: 0.8217 - loss: 0.5186 - precision_1: 0.7360 - recall_1: 0.7444 - val_accuracy: 0.7612 - val_auc_1: 0.7806 - val_loss: 0.5456 - val_precision_1: 0.7016 - val_recall_1: 0.8723\n",
      "Epoch 38/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7581 - auc_1: 0.8241 - loss: 0.5166 - precision_1: 0.7397 - recall_1: 0.7420 - val_accuracy: 0.7607 - val_auc_1: 0.7840 - val_loss: 0.5438 - val_precision_1: 0.7005 - val_recall_1: 0.8742\n",
      "Epoch 39/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7538 - auc_1: 0.8201 - loss: 0.5204 - precision_1: 0.7352 - recall_1: 0.7370 - val_accuracy: 0.7603 - val_auc_1: 0.7811 - val_loss: 0.5408 - val_precision_1: 0.7000 - val_recall_1: 0.8742\n",
      "Epoch 40/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7501 - auc_1: 0.8217 - loss: 0.5186 - precision_1: 0.7301 - recall_1: 0.7356 - val_accuracy: 0.7598 - val_auc_1: 0.7795 - val_loss: 0.5468 - val_precision_1: 0.7004 - val_recall_1: 0.8714\n",
      "Epoch 41/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7535 - auc_1: 0.8226 - loss: 0.5178 - precision_1: 0.7332 - recall_1: 0.7404 - val_accuracy: 0.7607 - val_auc_1: 0.7812 - val_loss: 0.5469 - val_precision_1: 0.7008 - val_recall_1: 0.8733\n",
      "Epoch 42/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7526 - auc_1: 0.8212 - loss: 0.5189 - precision_1: 0.7321 - recall_1: 0.7396 - val_accuracy: 0.7607 - val_auc_1: 0.7814 - val_loss: 0.5431 - val_precision_1: 0.7002 - val_recall_1: 0.8751\n",
      "Epoch 43/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7565 - auc_1: 0.8258 - loss: 0.5137 - precision_1: 0.7386 - recall_1: 0.7389 - val_accuracy: 0.7607 - val_auc_1: 0.7810 - val_loss: 0.5466 - val_precision_1: 0.7008 - val_recall_1: 0.8733\n",
      "Epoch 44/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7580 - auc_1: 0.8270 - loss: 0.5121 - precision_1: 0.7388 - recall_1: 0.7437 - val_accuracy: 0.7607 - val_auc_1: 0.7809 - val_loss: 0.5454 - val_precision_1: 0.7011 - val_recall_1: 0.8723\n",
      "Epoch 45/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7501 - auc_1: 0.8222 - loss: 0.5178 - precision_1: 0.7325 - recall_1: 0.7305 - val_accuracy: 0.7607 - val_auc_1: 0.7830 - val_loss: 0.5419 - val_precision_1: 0.7005 - val_recall_1: 0.8742\n",
      "Epoch 46/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7559 - auc_1: 0.8254 - loss: 0.5149 - precision_1: 0.7386 - recall_1: 0.7370 - val_accuracy: 0.7585 - val_auc_1: 0.7809 - val_loss: 0.5446 - val_precision_1: 0.7012 - val_recall_1: 0.8639\n",
      "Epoch 47/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7637 - auc_1: 0.8308 - loss: 0.5079 - precision_1: 0.7464 - recall_1: 0.7466 - val_accuracy: 0.7594 - val_auc_1: 0.7821 - val_loss: 0.5493 - val_precision_1: 0.6999 - val_recall_1: 0.8714\n",
      "Epoch 48/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7538 - auc_1: 0.8270 - loss: 0.5123 - precision_1: 0.7352 - recall_1: 0.7370 - val_accuracy: 0.7567 - val_auc_1: 0.7809 - val_loss: 0.5441 - val_precision_1: 0.6997 - val_recall_1: 0.8621\n",
      "Epoch 49/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7579 - auc_1: 0.8293 - loss: 0.5100 - precision_1: 0.7402 - recall_1: 0.7404 - val_accuracy: 0.7571 - val_auc_1: 0.7797 - val_loss: 0.5494 - val_precision_1: 0.7030 - val_recall_1: 0.8537\n",
      "Epoch 50/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7561 - auc_1: 0.8260 - loss: 0.5139 - precision_1: 0.7385 - recall_1: 0.7380 - val_accuracy: 0.7594 - val_auc_1: 0.7828 - val_loss: 0.5440 - val_precision_1: 0.7011 - val_recall_1: 0.8677\n",
      "Epoch 51/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7578 - auc_1: 0.8289 - loss: 0.5101 - precision_1: 0.7400 - recall_1: 0.7404 - val_accuracy: 0.7589 - val_auc_1: 0.7822 - val_loss: 0.5474 - val_precision_1: 0.7055 - val_recall_1: 0.8527\n",
      "Epoch 52/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7568 - auc_1: 0.8288 - loss: 0.5108 - precision_1: 0.7381 - recall_1: 0.7411 - val_accuracy: 0.7585 - val_auc_1: 0.7802 - val_loss: 0.5490 - val_precision_1: 0.7009 - val_recall_1: 0.8649\n",
      "Epoch 53/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7560 - auc_1: 0.8283 - loss: 0.5108 - precision_1: 0.7397 - recall_1: 0.7351 - val_accuracy: 0.7598 - val_auc_1: 0.7809 - val_loss: 0.5509 - val_precision_1: 0.7016 - val_recall_1: 0.8677\n",
      "Epoch 54/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7602 - auc_1: 0.8316 - loss: 0.5073 - precision_1: 0.7423 - recall_1: 0.7432 - val_accuracy: 0.7567 - val_auc_1: 0.7802 - val_loss: 0.5528 - val_precision_1: 0.7003 - val_recall_1: 0.8602\n",
      "Epoch 55/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7569 - auc_1: 0.8299 - loss: 0.5084 - precision_1: 0.7389 - recall_1: 0.7396 - val_accuracy: 0.7598 - val_auc_1: 0.7810 - val_loss: 0.5470 - val_precision_1: 0.6998 - val_recall_1: 0.8733\n",
      "Epoch 56/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7621 - auc_1: 0.8300 - loss: 0.5089 - precision_1: 0.7457 - recall_1: 0.7425 - val_accuracy: 0.7607 - val_auc_1: 0.7788 - val_loss: 0.5503 - val_precision_1: 0.7014 - val_recall_1: 0.8714\n",
      "Epoch 57/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7612 - auc_1: 0.8323 - loss: 0.5053 - precision_1: 0.7438 - recall_1: 0.7435 - val_accuracy: 0.7576 - val_auc_1: 0.7774 - val_loss: 0.5578 - val_precision_1: 0.6998 - val_recall_1: 0.8649\n",
      "Epoch 58/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7577 - auc_1: 0.8302 - loss: 0.5083 - precision_1: 0.7420 - recall_1: 0.7358 - val_accuracy: 0.7612 - val_auc_1: 0.7805 - val_loss: 0.5510 - val_precision_1: 0.7032 - val_recall_1: 0.8677\n",
      "Epoch 59/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7577 - auc_1: 0.8323 - loss: 0.5054 - precision_1: 0.7407 - recall_1: 0.7384 - val_accuracy: 0.7594 - val_auc_1: 0.7788 - val_loss: 0.5454 - val_precision_1: 0.7014 - val_recall_1: 0.8667\n",
      "Epoch 60/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7615 - auc_1: 0.8338 - loss: 0.5036 - precision_1: 0.7431 - recall_1: 0.7461 - val_accuracy: 0.7598 - val_auc_1: 0.7826 - val_loss: 0.5496 - val_precision_1: 0.7013 - val_recall_1: 0.8686\n",
      "Epoch 61/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7603 - auc_1: 0.8335 - loss: 0.5051 - precision_1: 0.7450 - recall_1: 0.7382 - val_accuracy: 0.7603 - val_auc_1: 0.7794 - val_loss: 0.5536 - val_precision_1: 0.7043 - val_recall_1: 0.8611\n",
      "Epoch 62/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7635 - auc_1: 0.8324 - loss: 0.5054 - precision_1: 0.7481 - recall_1: 0.7425 - val_accuracy: 0.7589 - val_auc_1: 0.7772 - val_loss: 0.5482 - val_precision_1: 0.7027 - val_recall_1: 0.8611\n",
      "Epoch 63/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7589 - auc_1: 0.8317 - loss: 0.5064 - precision_1: 0.7429 - recall_1: 0.7380 - val_accuracy: 0.7558 - val_auc_1: 0.7780 - val_loss: 0.5501 - val_precision_1: 0.7011 - val_recall_1: 0.8546\n",
      "Epoch 64/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7645 - auc_1: 0.8361 - loss: 0.5011 - precision_1: 0.7486 - recall_1: 0.7447 - val_accuracy: 0.7589 - val_auc_1: 0.7803 - val_loss: 0.5542 - val_precision_1: 0.7042 - val_recall_1: 0.8565\n",
      "Epoch 65/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7608 - auc_1: 0.8353 - loss: 0.5009 - precision_1: 0.7429 - recall_1: 0.7442 - val_accuracy: 0.7576 - val_auc_1: 0.7777 - val_loss: 0.5531 - val_precision_1: 0.7011 - val_recall_1: 0.8611\n",
      "Epoch 66/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7636 - auc_1: 0.8382 - loss: 0.4991 - precision_1: 0.7444 - recall_1: 0.7504 - val_accuracy: 0.7594 - val_auc_1: 0.7769 - val_loss: 0.5528 - val_precision_1: 0.7035 - val_recall_1: 0.8602\n",
      "Epoch 67/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7655 - auc_1: 0.8390 - loss: 0.4971 - precision_1: 0.7498 - recall_1: 0.7456 - val_accuracy: 0.7585 - val_auc_1: 0.7803 - val_loss: 0.5501 - val_precision_1: 0.7027 - val_recall_1: 0.8593\n",
      "Epoch 68/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7605 - auc_1: 0.8359 - loss: 0.5012 - precision_1: 0.7418 - recall_1: 0.7454 - val_accuracy: 0.7518 - val_auc_1: 0.7780 - val_loss: 0.5515 - val_precision_1: 0.7021 - val_recall_1: 0.8369\n",
      "Epoch 69/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7615 - auc_1: 0.8365 - loss: 0.5000 - precision_1: 0.7467 - recall_1: 0.7387 - val_accuracy: 0.7603 - val_auc_1: 0.7792 - val_loss: 0.5500 - val_precision_1: 0.7033 - val_recall_1: 0.8639\n",
      "Epoch 70/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7621 - auc_1: 0.8367 - loss: 0.5002 - precision_1: 0.7481 - recall_1: 0.7377 - val_accuracy: 0.7589 - val_auc_1: 0.7801 - val_loss: 0.5492 - val_precision_1: 0.7048 - val_recall_1: 0.8546\n",
      "Epoch 71/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7606 - auc_1: 0.8342 - loss: 0.5034 - precision_1: 0.7459 - recall_1: 0.7375 - val_accuracy: 0.7531 - val_auc_1: 0.7789 - val_loss: 0.5491 - val_precision_1: 0.7034 - val_recall_1: 0.8378\n",
      "Epoch 72/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7603 - auc_1: 0.8381 - loss: 0.4984 - precision_1: 0.7446 - recall_1: 0.7389 - val_accuracy: 0.7585 - val_auc_1: 0.7787 - val_loss: 0.5538 - val_precision_1: 0.7027 - val_recall_1: 0.8593\n",
      "Epoch 73/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7643 - auc_1: 0.8369 - loss: 0.5006 - precision_1: 0.7512 - recall_1: 0.7389 - val_accuracy: 0.7576 - val_auc_1: 0.7787 - val_loss: 0.5513 - val_precision_1: 0.7008 - val_recall_1: 0.8621\n",
      "Epoch 74/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7665 - auc_1: 0.8414 - loss: 0.4945 - precision_1: 0.7508 - recall_1: 0.7468 - val_accuracy: 0.7607 - val_auc_1: 0.7793 - val_loss: 0.5513 - val_precision_1: 0.7014 - val_recall_1: 0.8714\n",
      "Epoch 75/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7634 - auc_1: 0.8401 - loss: 0.4953 - precision_1: 0.7477 - recall_1: 0.7430 - val_accuracy: 0.7594 - val_auc_1: 0.7797 - val_loss: 0.5573 - val_precision_1: 0.7029 - val_recall_1: 0.8621\n",
      "Epoch 76/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7629 - auc_1: 0.8379 - loss: 0.4984 - precision_1: 0.7472 - recall_1: 0.7425 - val_accuracy: 0.7585 - val_auc_1: 0.7770 - val_loss: 0.5613 - val_precision_1: 0.7018 - val_recall_1: 0.8621\n",
      "Epoch 77/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7686 - auc_1: 0.8410 - loss: 0.4945 - precision_1: 0.7548 - recall_1: 0.7456 - val_accuracy: 0.7531 - val_auc_1: 0.7780 - val_loss: 0.5537 - val_precision_1: 0.7019 - val_recall_1: 0.8425\n",
      "Epoch 78/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7673 - auc_1: 0.8422 - loss: 0.4931 - precision_1: 0.7510 - recall_1: 0.7490 - val_accuracy: 0.7545 - val_auc_1: 0.7762 - val_loss: 0.5565 - val_precision_1: 0.7054 - val_recall_1: 0.8369\n",
      "Epoch 79/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7657 - auc_1: 0.8401 - loss: 0.4951 - precision_1: 0.7526 - recall_1: 0.7408 - val_accuracy: 0.7527 - val_auc_1: 0.7781 - val_loss: 0.5612 - val_precision_1: 0.7023 - val_recall_1: 0.8397\n",
      "Epoch 80/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7660 - auc_1: 0.8402 - loss: 0.4962 - precision_1: 0.7532 - recall_1: 0.7404 - val_accuracy: 0.7554 - val_auc_1: 0.7754 - val_loss: 0.5576 - val_precision_1: 0.7021 - val_recall_1: 0.8500\n",
      "Epoch 81/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7669 - auc_1: 0.8409 - loss: 0.4945 - precision_1: 0.7532 - recall_1: 0.7432 - val_accuracy: 0.7554 - val_auc_1: 0.7760 - val_loss: 0.5623 - val_precision_1: 0.7030 - val_recall_1: 0.8472\n",
      "Epoch 82/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7640 - auc_1: 0.8385 - loss: 0.4978 - precision_1: 0.7500 - recall_1: 0.7401 - val_accuracy: 0.7580 - val_auc_1: 0.7758 - val_loss: 0.5581 - val_precision_1: 0.7044 - val_recall_1: 0.8527\n",
      "Epoch 83/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7677 - auc_1: 0.8416 - loss: 0.4936 - precision_1: 0.7522 - recall_1: 0.7480 - val_accuracy: 0.7527 - val_auc_1: 0.7762 - val_loss: 0.5616 - val_precision_1: 0.7026 - val_recall_1: 0.8388\n",
      "Epoch 84/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7698 - auc_1: 0.8423 - loss: 0.4924 - precision_1: 0.7562 - recall_1: 0.7466 - val_accuracy: 0.7576 - val_auc_1: 0.7761 - val_loss: 0.5563 - val_precision_1: 0.7035 - val_recall_1: 0.8537\n",
      "Epoch 85/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7656 - auc_1: 0.8412 - loss: 0.4946 - precision_1: 0.7504 - recall_1: 0.7447 - val_accuracy: 0.7594 - val_auc_1: 0.7771 - val_loss: 0.5554 - val_precision_1: 0.7070 - val_recall_1: 0.8500\n",
      "Epoch 86/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7691 - auc_1: 0.8398 - loss: 0.4964 - precision_1: 0.7563 - recall_1: 0.7442 - val_accuracy: 0.7536 - val_auc_1: 0.7747 - val_loss: 0.5594 - val_precision_1: 0.7037 - val_recall_1: 0.8388\n",
      "Epoch 87/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7681 - auc_1: 0.8418 - loss: 0.4932 - precision_1: 0.7527 - recall_1: 0.7480 - val_accuracy: 0.7594 - val_auc_1: 0.7754 - val_loss: 0.5578 - val_precision_1: 0.7026 - val_recall_1: 0.8630\n",
      "Epoch 88/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7644 - auc_1: 0.8414 - loss: 0.4931 - precision_1: 0.7512 - recall_1: 0.7392 - val_accuracy: 0.7446 - val_auc_1: 0.7721 - val_loss: 0.5696 - val_precision_1: 0.7002 - val_recall_1: 0.8164\n",
      "Epoch 89/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7689 - auc_1: 0.8419 - loss: 0.4934 - precision_1: 0.7550 - recall_1: 0.7461 - val_accuracy: 0.7558 - val_auc_1: 0.7746 - val_loss: 0.5623 - val_precision_1: 0.7032 - val_recall_1: 0.8481\n",
      "Epoch 90/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7700 - auc_1: 0.8443 - loss: 0.4905 - precision_1: 0.7571 - recall_1: 0.7456 - val_accuracy: 0.7558 - val_auc_1: 0.7783 - val_loss: 0.5549 - val_precision_1: 0.7068 - val_recall_1: 0.8378\n",
      "Epoch 91/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7688 - auc_1: 0.8427 - loss: 0.4920 - precision_1: 0.7555 - recall_1: 0.7447 - val_accuracy: 0.7576 - val_auc_1: 0.7770 - val_loss: 0.5612 - val_precision_1: 0.7023 - val_recall_1: 0.8574\n",
      "Epoch 92/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7713 - auc_1: 0.8440 - loss: 0.4905 - precision_1: 0.7575 - recall_1: 0.7490 - val_accuracy: 0.7585 - val_auc_1: 0.7770 - val_loss: 0.5640 - val_precision_1: 0.7027 - val_recall_1: 0.8593\n",
      "Epoch 93/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7706 - auc_1: 0.8443 - loss: 0.4893 - precision_1: 0.7542 - recall_1: 0.7533 - val_accuracy: 0.7545 - val_auc_1: 0.7762 - val_loss: 0.5573 - val_precision_1: 0.7007 - val_recall_1: 0.8509\n",
      "Epoch 94/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7671 - auc_1: 0.8406 - loss: 0.4951 - precision_1: 0.7522 - recall_1: 0.7459 - val_accuracy: 0.7500 - val_auc_1: 0.7748 - val_loss: 0.5566 - val_precision_1: 0.7002 - val_recall_1: 0.8360\n",
      "Epoch 95/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7688 - auc_1: 0.8432 - loss: 0.4918 - precision_1: 0.7545 - recall_1: 0.7466 - val_accuracy: 0.7513 - val_auc_1: 0.7753 - val_loss: 0.5615 - val_precision_1: 0.7022 - val_recall_1: 0.8350\n",
      "Epoch 96/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7708 - auc_1: 0.8439 - loss: 0.4902 - precision_1: 0.7551 - recall_1: 0.7519 - val_accuracy: 0.7585 - val_auc_1: 0.7765 - val_loss: 0.5578 - val_precision_1: 0.7052 - val_recall_1: 0.8518\n",
      "Epoch 97/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7739 - auc_1: 0.8455 - loss: 0.4893 - precision_1: 0.7596 - recall_1: 0.7531 - val_accuracy: 0.7585 - val_auc_1: 0.7764 - val_loss: 0.5582 - val_precision_1: 0.7046 - val_recall_1: 0.8537\n",
      "Epoch 98/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7669 - auc_1: 0.8421 - loss: 0.4927 - precision_1: 0.7543 - recall_1: 0.7411 - val_accuracy: 0.7558 - val_auc_1: 0.7772 - val_loss: 0.5541 - val_precision_1: 0.7029 - val_recall_1: 0.8490\n",
      "Epoch 99/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7700 - auc_1: 0.8453 - loss: 0.4885 - precision_1: 0.7549 - recall_1: 0.7497 - val_accuracy: 0.7571 - val_auc_1: 0.7765 - val_loss: 0.5551 - val_precision_1: 0.7036 - val_recall_1: 0.8518\n",
      "Epoch 100/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7679 - auc_1: 0.8449 - loss: 0.4885 - precision_1: 0.7522 - recall_1: 0.7483 - val_accuracy: 0.7545 - val_auc_1: 0.7763 - val_loss: 0.5627 - val_precision_1: 0.7035 - val_recall_1: 0.8425\n",
      "Epoch 101/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7693 - auc_1: 0.8419 - loss: 0.4935 - precision_1: 0.7529 - recall_1: 0.7516 - val_accuracy: 0.7536 - val_auc_1: 0.7754 - val_loss: 0.5585 - val_precision_1: 0.7037 - val_recall_1: 0.8388\n",
      "Epoch 102/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7717 - auc_1: 0.8459 - loss: 0.4887 - precision_1: 0.7612 - recall_1: 0.7430 - val_accuracy: 0.7491 - val_auc_1: 0.7737 - val_loss: 0.5660 - val_precision_1: 0.7004 - val_recall_1: 0.8322\n",
      "Epoch 103/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7640 - auc_1: 0.8426 - loss: 0.4918 - precision_1: 0.7516 - recall_1: 0.7370 - val_accuracy: 0.7549 - val_auc_1: 0.7776 - val_loss: 0.5564 - val_precision_1: 0.7009 - val_recall_1: 0.8518\n",
      "Epoch 104/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7728 - auc_1: 0.8439 - loss: 0.4904 - precision_1: 0.7573 - recall_1: 0.7540 - val_accuracy: 0.7504 - val_auc_1: 0.7747 - val_loss: 0.5675 - val_precision_1: 0.7024 - val_recall_1: 0.8313\n",
      "Epoch 105/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7743 - auc_1: 0.8466 - loss: 0.4875 - precision_1: 0.7603 - recall_1: 0.7531 - val_accuracy: 0.7500 - val_auc_1: 0.7756 - val_loss: 0.5627 - val_precision_1: 0.6993 - val_recall_1: 0.8388\n",
      "Epoch 106/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7767 - auc_1: 0.8469 - loss: 0.4868 - precision_1: 0.7612 - recall_1: 0.7588 - val_accuracy: 0.7496 - val_auc_1: 0.7765 - val_loss: 0.5641 - val_precision_1: 0.7016 - val_recall_1: 0.8304\n",
      "Epoch 107/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7690 - auc_1: 0.8453 - loss: 0.4885 - precision_1: 0.7548 - recall_1: 0.7468 - val_accuracy: 0.7531 - val_auc_1: 0.7796 - val_loss: 0.5555 - val_precision_1: 0.7022 - val_recall_1: 0.8416\n",
      "Epoch 108/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7714 - auc_1: 0.8424 - loss: 0.4933 - precision_1: 0.7593 - recall_1: 0.7459 - val_accuracy: 0.7536 - val_auc_1: 0.7804 - val_loss: 0.5533 - val_precision_1: 0.7043 - val_recall_1: 0.8369\n",
      "Epoch 109/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7711 - auc_1: 0.8452 - loss: 0.4897 - precision_1: 0.7573 - recall_1: 0.7487 - val_accuracy: 0.7500 - val_auc_1: 0.7774 - val_loss: 0.5580 - val_precision_1: 0.7005 - val_recall_1: 0.8350\n",
      "Epoch 110/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7676 - auc_1: 0.8432 - loss: 0.4916 - precision_1: 0.7536 - recall_1: 0.7449 - val_accuracy: 0.7567 - val_auc_1: 0.7787 - val_loss: 0.5553 - val_precision_1: 0.7015 - val_recall_1: 0.8565\n",
      "Epoch 111/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7637 - auc_1: 0.8429 - loss: 0.4909 - precision_1: 0.7489 - recall_1: 0.7416 - val_accuracy: 0.7478 - val_auc_1: 0.7752 - val_loss: 0.5612 - val_precision_1: 0.6984 - val_recall_1: 0.8332\n",
      "Epoch 112/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7715 - auc_1: 0.8466 - loss: 0.4862 - precision_1: 0.7566 - recall_1: 0.7514 - val_accuracy: 0.7531 - val_auc_1: 0.7773 - val_loss: 0.5691 - val_precision_1: 0.7003 - val_recall_1: 0.8472\n",
      "Epoch 113/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_1: 0.8475 - loss: 0.4862 - precision_1: 0.7596 - recall_1: 0.7521 - val_accuracy: 0.7491 - val_auc_1: 0.7753 - val_loss: 0.5651 - val_precision_1: 0.7026 - val_recall_1: 0.8257\n",
      "Epoch 114/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7747 - auc_1: 0.8487 - loss: 0.4841 - precision_1: 0.7604 - recall_1: 0.7540 - val_accuracy: 0.7473 - val_auc_1: 0.7769 - val_loss: 0.5590 - val_precision_1: 0.7004 - val_recall_1: 0.8257\n",
      "Epoch 115/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7696 - auc_1: 0.8423 - loss: 0.4930 - precision_1: 0.7554 - recall_1: 0.7478 - val_accuracy: 0.7473 - val_auc_1: 0.7772 - val_loss: 0.5604 - val_precision_1: 0.7001 - val_recall_1: 0.8267\n",
      "Epoch 116/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7754 - auc_1: 0.8467 - loss: 0.4867 - precision_1: 0.7622 - recall_1: 0.7531 - val_accuracy: 0.7478 - val_auc_1: 0.7745 - val_loss: 0.5642 - val_precision_1: 0.7006 - val_recall_1: 0.8267\n",
      "Epoch 117/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7753 - auc_1: 0.8485 - loss: 0.4848 - precision_1: 0.7634 - recall_1: 0.7504 - val_accuracy: 0.7469 - val_auc_1: 0.7754 - val_loss: 0.5639 - val_precision_1: 0.6940 - val_recall_1: 0.8434\n",
      "Epoch 118/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7733 - auc_1: 0.8490 - loss: 0.4835 - precision_1: 0.7606 - recall_1: 0.7495 - val_accuracy: 0.7424 - val_auc_1: 0.7740 - val_loss: 0.5666 - val_precision_1: 0.6956 - val_recall_1: 0.8220\n",
      "Epoch 119/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7708 - auc_1: 0.8487 - loss: 0.4843 - precision_1: 0.7567 - recall_1: 0.7487 - val_accuracy: 0.7536 - val_auc_1: 0.7781 - val_loss: 0.5677 - val_precision_1: 0.7015 - val_recall_1: 0.8453\n",
      "Epoch 120/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7731 - auc_1: 0.8452 - loss: 0.4895 - precision_1: 0.7586 - recall_1: 0.7526 - val_accuracy: 0.7487 - val_auc_1: 0.7742 - val_loss: 0.5643 - val_precision_1: 0.6989 - val_recall_1: 0.8350\n",
      "Epoch 121/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7751 - auc_1: 0.8483 - loss: 0.4846 - precision_1: 0.7639 - recall_1: 0.7487 - val_accuracy: 0.7460 - val_auc_1: 0.7757 - val_loss: 0.5610 - val_precision_1: 0.7003 - val_recall_1: 0.8211\n",
      "Epoch 122/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.7741 - auc_1: 0.8513 - loss: 0.4800 - precision_1: 0.7623 - recall_1: 0.7487 - val_accuracy: 0.7420 - val_auc_1: 0.7740 - val_loss: 0.5699 - val_precision_1: 0.6969 - val_recall_1: 0.8164\n",
      "Epoch 123/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7682 - auc_1: 0.8469 - loss: 0.4860 - precision_1: 0.7505 - recall_1: 0.7528 - val_accuracy: 0.7496 - val_auc_1: 0.7752 - val_loss: 0.5695 - val_precision_1: 0.7003 - val_recall_1: 0.8341\n",
      "Epoch 124/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7710 - auc_1: 0.8462 - loss: 0.4872 - precision_1: 0.7581 - recall_1: 0.7468 - val_accuracy: 0.7446 - val_auc_1: 0.7733 - val_loss: 0.5702 - val_precision_1: 0.6987 - val_recall_1: 0.8211\n",
      "Epoch 125/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7749 - auc_1: 0.8504 - loss: 0.4815 - precision_1: 0.7608 - recall_1: 0.7540 - val_accuracy: 0.7518 - val_auc_1: 0.7725 - val_loss: 0.5717 - val_precision_1: 0.6969 - val_recall_1: 0.8527\n",
      "Epoch 126/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7775 - auc_1: 0.8535 - loss: 0.4772 - precision_1: 0.7632 - recall_1: 0.7574 - val_accuracy: 0.7442 - val_auc_1: 0.7730 - val_loss: 0.5707 - val_precision_1: 0.7006 - val_recall_1: 0.8136\n",
      "Epoch 127/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7705 - auc_1: 0.8486 - loss: 0.4835 - precision_1: 0.7556 - recall_1: 0.7502 - val_accuracy: 0.7518 - val_auc_1: 0.7726 - val_loss: 0.5642 - val_precision_1: 0.7037 - val_recall_1: 0.8322\n",
      "Epoch 128/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7737 - auc_1: 0.8491 - loss: 0.4834 - precision_1: 0.7570 - recall_1: 0.7574 - val_accuracy: 0.7446 - val_auc_1: 0.7739 - val_loss: 0.5690 - val_precision_1: 0.6968 - val_recall_1: 0.8267\n",
      "Epoch 129/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7691 - auc_1: 0.8477 - loss: 0.4857 - precision_1: 0.7553 - recall_1: 0.7461 - val_accuracy: 0.7487 - val_auc_1: 0.7760 - val_loss: 0.5652 - val_precision_1: 0.6986 - val_recall_1: 0.8360\n",
      "Epoch 130/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7717 - auc_1: 0.8474 - loss: 0.4854 - precision_1: 0.7597 - recall_1: 0.7459 - val_accuracy: 0.7464 - val_auc_1: 0.7740 - val_loss: 0.5618 - val_precision_1: 0.7015 - val_recall_1: 0.8192\n",
      "Epoch 131/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_1: 0.8483 - loss: 0.4843 - precision_1: 0.7644 - recall_1: 0.7538 - val_accuracy: 0.7469 - val_auc_1: 0.7756 - val_loss: 0.5626 - val_precision_1: 0.6980 - val_recall_1: 0.8313\n",
      "Epoch 132/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7766 - auc_1: 0.8486 - loss: 0.4839 - precision_1: 0.7629 - recall_1: 0.7552 - val_accuracy: 0.7513 - val_auc_1: 0.7732 - val_loss: 0.5723 - val_precision_1: 0.7012 - val_recall_1: 0.8378\n",
      "Epoch 133/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7701 - auc_1: 0.8480 - loss: 0.4851 - precision_1: 0.7555 - recall_1: 0.7490 - val_accuracy: 0.7500 - val_auc_1: 0.7730 - val_loss: 0.5674 - val_precision_1: 0.6969 - val_recall_1: 0.8462\n",
      "Epoch 134/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7738 - auc_1: 0.8488 - loss: 0.4837 - precision_1: 0.7614 - recall_1: 0.7492 - val_accuracy: 0.7437 - val_auc_1: 0.7733 - val_loss: 0.5656 - val_precision_1: 0.6979 - val_recall_1: 0.8201\n",
      "Epoch 135/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7768 - auc_1: 0.8547 - loss: 0.4749 - precision_1: 0.7638 - recall_1: 0.7543 - val_accuracy: 0.7504 - val_auc_1: 0.7731 - val_loss: 0.5689 - val_precision_1: 0.7017 - val_recall_1: 0.8332\n",
      "Epoch 136/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7722 - auc_1: 0.8506 - loss: 0.4805 - precision_1: 0.7608 - recall_1: 0.7456 - val_accuracy: 0.7522 - val_auc_1: 0.7768 - val_loss: 0.5659 - val_precision_1: 0.7002 - val_recall_1: 0.8444\n",
      "Epoch 137/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7741 - auc_1: 0.8485 - loss: 0.4841 - precision_1: 0.7601 - recall_1: 0.7528 - val_accuracy: 0.7487 - val_auc_1: 0.7751 - val_loss: 0.5734 - val_precision_1: 0.6998 - val_recall_1: 0.8322\n",
      "Epoch 138/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7762 - auc_1: 0.8533 - loss: 0.4767 - precision_1: 0.7612 - recall_1: 0.7574 - val_accuracy: 0.7357 - val_auc_1: 0.7731 - val_loss: 0.5739 - val_precision_1: 0.6986 - val_recall_1: 0.7884\n",
      "Epoch 139/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7717 - auc_1: 0.8503 - loss: 0.4820 - precision_1: 0.7606 - recall_1: 0.7442 - val_accuracy: 0.7330 - val_auc_1: 0.7709 - val_loss: 0.5763 - val_precision_1: 0.6936 - val_recall_1: 0.7931\n",
      "Epoch 140/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7703 - auc_1: 0.8466 - loss: 0.4859 - precision_1: 0.7571 - recall_1: 0.7466 - val_accuracy: 0.7509 - val_auc_1: 0.7754 - val_loss: 0.5719 - val_precision_1: 0.7013 - val_recall_1: 0.8360\n",
      "Epoch 141/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7750 - auc_1: 0.8512 - loss: 0.4806 - precision_1: 0.7628 - recall_1: 0.7504 - val_accuracy: 0.7513 - val_auc_1: 0.7759 - val_loss: 0.5686 - val_precision_1: 0.6991 - val_recall_1: 0.8444\n",
      "Epoch 142/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7808 - auc_1: 0.8520 - loss: 0.4796 - precision_1: 0.7692 - recall_1: 0.7566 - val_accuracy: 0.7446 - val_auc_1: 0.7745 - val_loss: 0.5721 - val_precision_1: 0.6962 - val_recall_1: 0.8285\n",
      "Epoch 143/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7778 - auc_1: 0.8554 - loss: 0.4742 - precision_1: 0.7658 - recall_1: 0.7535 - val_accuracy: 0.7384 - val_auc_1: 0.7737 - val_loss: 0.5738 - val_precision_1: 0.6968 - val_recall_1: 0.8034\n",
      "Epoch 144/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7765 - auc_1: 0.8514 - loss: 0.4796 - precision_1: 0.7621 - recall_1: 0.7564 - val_accuracy: 0.7473 - val_auc_1: 0.7770 - val_loss: 0.5719 - val_precision_1: 0.6985 - val_recall_1: 0.8313\n",
      "Epoch 145/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7720 - auc_1: 0.8509 - loss: 0.4810 - precision_1: 0.7614 - recall_1: 0.7437 - val_accuracy: 0.7437 - val_auc_1: 0.7753 - val_loss: 0.5689 - val_precision_1: 0.6972 - val_recall_1: 0.8220\n",
      "Epoch 146/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7790 - auc_1: 0.8531 - loss: 0.4783 - precision_1: 0.7649 - recall_1: 0.7590 - val_accuracy: 0.7326 - val_auc_1: 0.7721 - val_loss: 0.5748 - val_precision_1: 0.6930 - val_recall_1: 0.7931\n",
      "Epoch 147/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_1: 0.8517 - loss: 0.4799 - precision_1: 0.7665 - recall_1: 0.7499 - val_accuracy: 0.7424 - val_auc_1: 0.7743 - val_loss: 0.5671 - val_precision_1: 0.6956 - val_recall_1: 0.8220\n",
      "Epoch 148/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7790 - auc_1: 0.8523 - loss: 0.4788 - precision_1: 0.7663 - recall_1: 0.7564 - val_accuracy: 0.7496 - val_auc_1: 0.7754 - val_loss: 0.5619 - val_precision_1: 0.6997 - val_recall_1: 0.8360\n",
      "Epoch 149/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7759 - auc_1: 0.8504 - loss: 0.4818 - precision_1: 0.7630 - recall_1: 0.7528 - val_accuracy: 0.7375 - val_auc_1: 0.7744 - val_loss: 0.5665 - val_precision_1: 0.6935 - val_recall_1: 0.8099\n",
      "Epoch 150/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7766 - auc_1: 0.8520 - loss: 0.4789 - precision_1: 0.7615 - recall_1: 0.7578 - val_accuracy: 0.7402 - val_auc_1: 0.7740 - val_loss: 0.5691 - val_precision_1: 0.6978 - val_recall_1: 0.8071\n",
      "Epoch 151/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7820 - auc_1: 0.8534 - loss: 0.4778 - precision_1: 0.7697 - recall_1: 0.7595 - val_accuracy: 0.7357 - val_auc_1: 0.7733 - val_loss: 0.5703 - val_precision_1: 0.7009 - val_recall_1: 0.7819\n",
      "Epoch 152/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7785 - auc_1: 0.8565 - loss: 0.4730 - precision_1: 0.7654 - recall_1: 0.7564 - val_accuracy: 0.7393 - val_auc_1: 0.7735 - val_loss: 0.5769 - val_precision_1: 0.6948 - val_recall_1: 0.8127\n",
      "Epoch 153/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7796 - auc_1: 0.8541 - loss: 0.4765 - precision_1: 0.7684 - recall_1: 0.7543 - val_accuracy: 0.7469 - val_auc_1: 0.7718 - val_loss: 0.5754 - val_precision_1: 0.7018 - val_recall_1: 0.8201\n",
      "Epoch 154/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7769 - auc_1: 0.8524 - loss: 0.4790 - precision_1: 0.7648 - recall_1: 0.7526 - val_accuracy: 0.7411 - val_auc_1: 0.7728 - val_loss: 0.5760 - val_precision_1: 0.6970 - val_recall_1: 0.8127\n",
      "Epoch 155/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7730 - auc_1: 0.8500 - loss: 0.4828 - precision_1: 0.7613 - recall_1: 0.7471 - val_accuracy: 0.7362 - val_auc_1: 0.7716 - val_loss: 0.5716 - val_precision_1: 0.6979 - val_recall_1: 0.7922\n",
      "Epoch 156/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7742 - auc_1: 0.8517 - loss: 0.4796 - precision_1: 0.7621 - recall_1: 0.7495 - val_accuracy: 0.7415 - val_auc_1: 0.7759 - val_loss: 0.5634 - val_precision_1: 0.7008 - val_recall_1: 0.8034\n",
      "Epoch 157/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7780 - auc_1: 0.8534 - loss: 0.4775 - precision_1: 0.7665 - recall_1: 0.7531 - val_accuracy: 0.7433 - val_auc_1: 0.7759 - val_loss: 0.5714 - val_precision_1: 0.6973 - val_recall_1: 0.8201\n",
      "Epoch 158/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7788 - auc_1: 0.8525 - loss: 0.4776 - precision_1: 0.7652 - recall_1: 0.7578 - val_accuracy: 0.7451 - val_auc_1: 0.7753 - val_loss: 0.5700 - val_precision_1: 0.6992 - val_recall_1: 0.8211\n",
      "Epoch 159/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7719 - auc_1: 0.8489 - loss: 0.4823 - precision_1: 0.7548 - recall_1: 0.7559 - val_accuracy: 0.7344 - val_auc_1: 0.7724 - val_loss: 0.5757 - val_precision_1: 0.6949 - val_recall_1: 0.7940\n",
      "Epoch 160/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7824 - auc_1: 0.8557 - loss: 0.4738 - precision_1: 0.7701 - recall_1: 0.7598 - val_accuracy: 0.7437 - val_auc_1: 0.7713 - val_loss: 0.5752 - val_precision_1: 0.6979 - val_recall_1: 0.8201\n",
      "Epoch 161/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7767 - auc_1: 0.8531 - loss: 0.4773 - precision_1: 0.7623 - recall_1: 0.7566 - val_accuracy: 0.7424 - val_auc_1: 0.7755 - val_loss: 0.5651 - val_precision_1: 0.6965 - val_recall_1: 0.8192\n",
      "Epoch 162/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7800 - auc_1: 0.8551 - loss: 0.4747 - precision_1: 0.7697 - recall_1: 0.7533 - val_accuracy: 0.7411 - val_auc_1: 0.7739 - val_loss: 0.5763 - val_precision_1: 0.6977 - val_recall_1: 0.8108\n",
      "Epoch 163/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7788 - auc_1: 0.8536 - loss: 0.4767 - precision_1: 0.7661 - recall_1: 0.7562 - val_accuracy: 0.7451 - val_auc_1: 0.7742 - val_loss: 0.5779 - val_precision_1: 0.6967 - val_recall_1: 0.8285\n",
      "Epoch 164/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7748 - auc_1: 0.8519 - loss: 0.4792 - precision_1: 0.7615 - recall_1: 0.7523 - val_accuracy: 0.7420 - val_auc_1: 0.7734 - val_loss: 0.5770 - val_precision_1: 0.6950 - val_recall_1: 0.8220\n",
      "Epoch 165/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7781 - auc_1: 0.8545 - loss: 0.4754 - precision_1: 0.7644 - recall_1: 0.7571 - val_accuracy: 0.7455 - val_auc_1: 0.7756 - val_loss: 0.5678 - val_precision_1: 0.6988 - val_recall_1: 0.8239\n",
      "Epoch 166/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7842 - auc_1: 0.8585 - loss: 0.4697 - precision_1: 0.7720 - recall_1: 0.7617 - val_accuracy: 0.7397 - val_auc_1: 0.7746 - val_loss: 0.5761 - val_precision_1: 0.6941 - val_recall_1: 0.8164\n",
      "Epoch 167/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7819 - auc_1: 0.8579 - loss: 0.4705 - precision_1: 0.7666 - recall_1: 0.7648 - val_accuracy: 0.7308 - val_auc_1: 0.7720 - val_loss: 0.5837 - val_precision_1: 0.6874 - val_recall_1: 0.8034\n",
      "Epoch 168/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7808 - auc_1: 0.8538 - loss: 0.4768 - precision_1: 0.7680 - recall_1: 0.7588 - val_accuracy: 0.7402 - val_auc_1: 0.7745 - val_loss: 0.5722 - val_precision_1: 0.6959 - val_recall_1: 0.8127\n",
      "Epoch 169/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7775 - auc_1: 0.8518 - loss: 0.4790 - precision_1: 0.7622 - recall_1: 0.7593 - val_accuracy: 0.7397 - val_auc_1: 0.7743 - val_loss: 0.5727 - val_precision_1: 0.6954 - val_recall_1: 0.8127\n",
      "Epoch 170/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7818 - auc_1: 0.8555 - loss: 0.4745 - precision_1: 0.7685 - recall_1: 0.7610 - val_accuracy: 0.7335 - val_auc_1: 0.7723 - val_loss: 0.5716 - val_precision_1: 0.6983 - val_recall_1: 0.7810\n",
      "Epoch 171/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7747 - auc_1: 0.8515 - loss: 0.4800 - precision_1: 0.7620 - recall_1: 0.7509 - val_accuracy: 0.7487 - val_auc_1: 0.7766 - val_loss: 0.5706 - val_precision_1: 0.6992 - val_recall_1: 0.8341\n",
      "Epoch 172/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_1: 0.8522 - loss: 0.4787 - precision_1: 0.7636 - recall_1: 0.7552 - val_accuracy: 0.7411 - val_auc_1: 0.7744 - val_loss: 0.5696 - val_precision_1: 0.6958 - val_recall_1: 0.8164\n",
      "Epoch 173/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7845 - auc_1: 0.8563 - loss: 0.4729 - precision_1: 0.7721 - recall_1: 0.7626 - val_accuracy: 0.7406 - val_auc_1: 0.7730 - val_loss: 0.5716 - val_precision_1: 0.6962 - val_recall_1: 0.8136\n",
      "Epoch 174/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7797 - auc_1: 0.8554 - loss: 0.4743 - precision_1: 0.7665 - recall_1: 0.7581 - val_accuracy: 0.7455 - val_auc_1: 0.7735 - val_loss: 0.5715 - val_precision_1: 0.6976 - val_recall_1: 0.8276\n",
      "Epoch 175/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7796 - auc_1: 0.8545 - loss: 0.4755 - precision_1: 0.7654 - recall_1: 0.7598 - val_accuracy: 0.7366 - val_auc_1: 0.7739 - val_loss: 0.5708 - val_precision_1: 0.6940 - val_recall_1: 0.8052\n",
      "Epoch 176/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7790 - auc_1: 0.8543 - loss: 0.4759 - precision_1: 0.7664 - recall_1: 0.7562 - val_accuracy: 0.7326 - val_auc_1: 0.7721 - val_loss: 0.5754 - val_precision_1: 0.6917 - val_recall_1: 0.7968\n",
      "Epoch 177/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7766 - auc_1: 0.8539 - loss: 0.4760 - precision_1: 0.7658 - recall_1: 0.7497 - val_accuracy: 0.7397 - val_auc_1: 0.7742 - val_loss: 0.5707 - val_precision_1: 0.6976 - val_recall_1: 0.8062\n",
      "Epoch 178/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7816 - auc_1: 0.8564 - loss: 0.4728 - precision_1: 0.7685 - recall_1: 0.7602 - val_accuracy: 0.7464 - val_auc_1: 0.7744 - val_loss: 0.5739 - val_precision_1: 0.7002 - val_recall_1: 0.8229\n",
      "Epoch 179/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7814 - auc_1: 0.8547 - loss: 0.4755 - precision_1: 0.7704 - recall_1: 0.7562 - val_accuracy: 0.7411 - val_auc_1: 0.7736 - val_loss: 0.5741 - val_precision_1: 0.6974 - val_recall_1: 0.8117\n",
      "Epoch 180/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7788 - auc_1: 0.8528 - loss: 0.4783 - precision_1: 0.7656 - recall_1: 0.7571 - val_accuracy: 0.7406 - val_auc_1: 0.7734 - val_loss: 0.5775 - val_precision_1: 0.7003 - val_recall_1: 0.8015\n",
      "Epoch 181/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7761 - auc_1: 0.8541 - loss: 0.4760 - precision_1: 0.7638 - recall_1: 0.7521 - val_accuracy: 0.7402 - val_auc_1: 0.7764 - val_loss: 0.5728 - val_precision_1: 0.6944 - val_recall_1: 0.8173\n",
      "Epoch 182/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7789 - auc_1: 0.8539 - loss: 0.4761 - precision_1: 0.7663 - recall_1: 0.7562 - val_accuracy: 0.7478 - val_auc_1: 0.7761 - val_loss: 0.5697 - val_precision_1: 0.6966 - val_recall_1: 0.8388\n",
      "Epoch 183/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7798 - auc_1: 0.8556 - loss: 0.4736 - precision_1: 0.7666 - recall_1: 0.7583 - val_accuracy: 0.7375 - val_auc_1: 0.7728 - val_loss: 0.5755 - val_precision_1: 0.6923 - val_recall_1: 0.8136\n",
      "Epoch 184/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7789 - auc_1: 0.8530 - loss: 0.4778 - precision_1: 0.7673 - recall_1: 0.7543 - val_accuracy: 0.7335 - val_auc_1: 0.7744 - val_loss: 0.5703 - val_precision_1: 0.6951 - val_recall_1: 0.7903\n",
      "Epoch 185/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7769 - auc_1: 0.8528 - loss: 0.4785 - precision_1: 0.7658 - recall_1: 0.7509 - val_accuracy: 0.7415 - val_auc_1: 0.7758 - val_loss: 0.5699 - val_precision_1: 0.6995 - val_recall_1: 0.8071\n",
      "Epoch 186/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7782 - auc_1: 0.8531 - loss: 0.4776 - precision_1: 0.7667 - recall_1: 0.7533 - val_accuracy: 0.7411 - val_auc_1: 0.7748 - val_loss: 0.5755 - val_precision_1: 0.6955 - val_recall_1: 0.8173\n",
      "Epoch 187/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7798 - auc_1: 0.8566 - loss: 0.4724 - precision_1: 0.7652 - recall_1: 0.7610 - val_accuracy: 0.7388 - val_auc_1: 0.7728 - val_loss: 0.5747 - val_precision_1: 0.6984 - val_recall_1: 0.8006\n",
      "Epoch 188/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7806 - auc_1: 0.8564 - loss: 0.4734 - precision_1: 0.7713 - recall_1: 0.7521 - val_accuracy: 0.7344 - val_auc_1: 0.7724 - val_loss: 0.5738 - val_precision_1: 0.7005 - val_recall_1: 0.7782\n",
      "Epoch 189/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7739 - auc_1: 0.8524 - loss: 0.4776 - precision_1: 0.7607 - recall_1: 0.7509 - val_accuracy: 0.7388 - val_auc_1: 0.7719 - val_loss: 0.5767 - val_precision_1: 0.6949 - val_recall_1: 0.8108\n",
      "Epoch 190/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7769 - auc_1: 0.8552 - loss: 0.4738 - precision_1: 0.7643 - recall_1: 0.7535 - val_accuracy: 0.7415 - val_auc_1: 0.7748 - val_loss: 0.5745 - val_precision_1: 0.6945 - val_recall_1: 0.8220\n",
      "Epoch 191/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7845 - auc_1: 0.8566 - loss: 0.4734 - precision_1: 0.7718 - recall_1: 0.7631 - val_accuracy: 0.7384 - val_auc_1: 0.7733 - val_loss: 0.5748 - val_precision_1: 0.6968 - val_recall_1: 0.8034\n",
      "Epoch 192/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7827 - auc_1: 0.8554 - loss: 0.4747 - precision_1: 0.7705 - recall_1: 0.7600 - val_accuracy: 0.7299 - val_auc_1: 0.7719 - val_loss: 0.5820 - val_precision_1: 0.6966 - val_recall_1: 0.7726\n",
      "Epoch 193/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7769 - auc_1: 0.8543 - loss: 0.4756 - precision_1: 0.7639 - recall_1: 0.7543 - val_accuracy: 0.7433 - val_auc_1: 0.7716 - val_loss: 0.5782 - val_precision_1: 0.7048 - val_recall_1: 0.7987\n",
      "Epoch 194/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7810 - auc_1: 0.8548 - loss: 0.4757 - precision_1: 0.7689 - recall_1: 0.7578 - val_accuracy: 0.7424 - val_auc_1: 0.7723 - val_loss: 0.5783 - val_precision_1: 0.7016 - val_recall_1: 0.8043\n",
      "Epoch 195/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7837 - auc_1: 0.8568 - loss: 0.4725 - precision_1: 0.7709 - recall_1: 0.7624 - val_accuracy: 0.7388 - val_auc_1: 0.7729 - val_loss: 0.5772 - val_precision_1: 0.7007 - val_recall_1: 0.7940\n",
      "Epoch 196/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7797 - auc_1: 0.8558 - loss: 0.4737 - precision_1: 0.7689 - recall_1: 0.7538 - val_accuracy: 0.7317 - val_auc_1: 0.7737 - val_loss: 0.5770 - val_precision_1: 0.6957 - val_recall_1: 0.7819\n",
      "Epoch 197/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7767 - auc_1: 0.8565 - loss: 0.4721 - precision_1: 0.7659 - recall_1: 0.7499 - val_accuracy: 0.7353 - val_auc_1: 0.7725 - val_loss: 0.5763 - val_precision_1: 0.6967 - val_recall_1: 0.7922\n",
      "Epoch 198/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7761 - auc_1: 0.8525 - loss: 0.4783 - precision_1: 0.7630 - recall_1: 0.7535 - val_accuracy: 0.7353 - val_auc_1: 0.7718 - val_loss: 0.5777 - val_precision_1: 0.6990 - val_recall_1: 0.7856\n",
      "Epoch 199/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7775 - auc_1: 0.8571 - loss: 0.4708 - precision_1: 0.7651 - recall_1: 0.7538 - val_accuracy: 0.7357 - val_auc_1: 0.7735 - val_loss: 0.5808 - val_precision_1: 0.6951 - val_recall_1: 0.7987\n",
      "Epoch 200/200\n",
      "\u001b[1m2240/2240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7783 - auc_1: 0.8548 - loss: 0.4751 - precision_1: 0.7652 - recall_1: 0.7564 - val_accuracy: 0.7353 - val_auc_1: 0.7729 - val_loss: 0.5780 - val_precision_1: 0.6983 - val_recall_1: 0.7875\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 1000, restore_best_weights = True)\n",
    "history = model.fit(\n",
    "    X_train , y_train ,\n",
    "    epochs = 200,\n",
    "    batch_size = 4,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65490eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7692 - auc_1: 0.7913 - loss: 0.5194 - precision_1: 0.6991 - recall_1: 0.8907\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, auc=model.evaluate(\n",
    "    X_test,y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3d2b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss \t\t : 0.5194490551948547\n",
      "accuracy \t : 0.7691740989685059\n",
      "precision \t : 0.6991137266159058\n",
      "recall \t\t : 0.8906621932983398\n",
      "auc \t\t : 0.7913320064544678\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss \\t\\t : {loss}\")\n",
    "print(f\"accuracy \\t : {accuracy}\")\n",
    "print(f\"precision \\t : {precision}\")\n",
    "print(f\"recall \\t\\t : {recall}\")\n",
    "print(f\"auc \\t\\t : {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924a789",
   "metadata": {},
   "source": [
    "Certainly! Here is a table summarizing the five evaluation metrics for binary classification models, their purpose, and what their values mean.\n",
    "\n",
    "| Metric | Purpose / What It Measures | Calculation | Interpretation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Loss** (Binary Cross-Entropy) | Measures the **error** between the predicted probabilities and the true labels. The value the model tries to minimize. | Based on the natural logarithm of predicted probabilities. | **Lower is better** (closer to $0.0$). A high value means the model is confidently wrong often. |\n",
    "| **Accuracy** | Measures the proportion of **total predictions** that were correct (both positive and negative). | $\\frac{\\text{TP} + \\text{TN}}{\\text{Total Samples}}$ | General measure of correctness. Can be misleading with imbalanced data. |\n",
    "| **Precision** | Measures the confidence of **positive predictions**. \"Of all predicted positive cases, how many were actually positive?\" | $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$ | **Higher is better.** Prioritized when **False Alarms** (False Positives) are costly. |\n",
    "| **Recall** | Measures the model's ability to **find all positive cases**. \"Of all actual positive cases, how many were correctly identified?\" | $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$ | **Higher is better.** Prioritized when **Missing a case** (False Negatives) is costly. |\n",
    "| **AUC** (Area Under the ROC Curve) | Measures the **overall model quality** across all possible thresholds, particularly useful for imbalanced data. | Probability of correctly ranking a random positive case higher than a random negative case. | Ranges from $0.5$ (random) to $1.0$ (perfect). **Higher is better.** |\n",
    "\n",
    "*(Note: TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1931c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7049635 ],\n",
       "       [0.7478007 ],\n",
       "       [0.7057483 ],\n",
       "       ...,\n",
       "       [0.06398952],\n",
       "       [0.8399402 ],\n",
       "       [0.7555299 ]], shape=(44800, 1), dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3a7c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_prob >= 0.5).astype(int) # to addjest to the recall and the precision can adjest thie threshold. but adjestion this can get tradeoffs. edit with caution.\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a105bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15764,  8046],\n",
       "       [ 2295, 18695]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefa0c0",
   "metadata": {},
   "source": [
    "The code you provided uses the `confusion_matrix` function from the `sklearn.metrics` module to generate a **Confusion Matrix**.\n",
    "\n",
    "This matrix is a table that summarizes the performance of your classification model by comparing the model's binary predictions (`y_pred`) against the actual true labels (`y_test`). It is the foundation for calculating metrics like Precision and Recall.\n",
    "\n",
    "***\n",
    "\n",
    "## What the Confusion Matrix Does\n",
    "\n",
    "The Confusion Matrix breaks down your model's predictions into four distinct categories:\n",
    "\n",
    "| | **Predicted: No Churn (0)** | **Predicted: Churn (1)** |\n",
    "| :--- | :--- | :--- |\n",
    "| **Actual: No Churn (0)** | **True Negative (TN)** | **False Positive (FP)** |\n",
    "| **Actual: Churn (1)** | **False Negative (FN)** | **True Positive (TP)** |\n",
    "\n",
    "### Explanation of the Four Components:\n",
    "\n",
    "1.  **True Positive (TP):** The model correctly predicted Churn (1) when the customer **actually churned** (1). (Good)\n",
    "2.  **True Negative (TN):** The model correctly predicted No Churn (0) when the customer **actually stayed** (0). (Good)\n",
    "3.  **False Positive (FP):** The model predicted Churn (1) when the customer **actually stayed** (0). This is a **False Alarm**. (Bad)\n",
    "4.  **False Negative (FN):** The model predicted No Churn (0) when the customer **actually churned** (1). This is a **Missed Opportunity**. (Bad)\n",
    "\n",
    "## Example Output\n",
    "\n",
    "When you run `confusion_matrix(y_test, y_pred)`, the output (using scikit-learn's standard format) will look like this, where the labels are organized as `[TN, FP], [FN, TP]`:\n",
    "\n",
    "$$\\begin{bmatrix} TN & FP \\\\ FN & TP \\end{bmatrix}$$\n",
    "\n",
    "For instance, if the output is:\n",
    "\n",
    "$$\\begin{bmatrix} 900 & 100 \\\\ 50 & 150 \\end{bmatrix}$$\n",
    "\n",
    "It means:\n",
    "\n",
    "* **900** customers were correctly predicted to stay (TN).\n",
    "* **100** customers were falsely predicted to churn (FP - False Alarms).\n",
    "* **50** customers were missed (FN - Missed Churners).\n",
    "* **150** customers were correctly predicted to churn (TP).\n",
    "\n",
    "This matrix gives you the raw counts needed to calculate all your key metrics: Precision, Recall, and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fc848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa409dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a530f0d",
   "metadata": {},
   "source": [
    "`Saving the model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d423bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as telco_churn_prediction_model_V1.0.keras\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'telco_churn_prediction_model_V1.0.keras'\n",
    "# Save the entire model\n",
    "model.save(model_filename) \n",
    "\n",
    "print(f\"Model saved successfully as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_TensorFlow_cpu_1 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
